---
title: "resampling ìœ¼ë¡œ ëª¨ë¸ í‰ê°€í•˜ê¸°"
weight: 3
tags: [rsample, parsnip, tune, workflows, yardstick]
categories: [resampling]
description: | 
  Measure model performance by generating different versions of the training data through resampling.
---
<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />







## ë“¤ì–´ê°€ê¸° {#intro}

ì§€ê¸ˆê¹Œì§€ [ëª¨ë¸ì„ ë§Œë“¤ê³ ](/start/models/) [recipe ë¡œ ë°ì´í„° ì „ì²˜ë¦¬](/start/recipes/) ë¥¼ í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ [parsnip ëª¨ë¸](https://tidymodels.github.io/parsnip/) ê³¼ [recipe](https://tidymodels.github.io/recipes/) ì„ ë¬¶ëŠ” ë°©ë²•ìœ¼ë¡œ [ ì›Œí¬í”Œë¡œ](/start/recipes/#fit-workflow) ë¥¼ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. íŠ¸ë ˆì¸ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´, ì´ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ì˜ˆì¸¡ì„ ì–¼ë§ˆë‚˜ ì˜ í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•  ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **resampling** í†µê³„ëŸ‰ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ì •ì˜í•˜ëŠ” ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

ì´ ì¥ì— ìˆëŠ” ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´,  ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì„ ì¸ìŠ¤í†¨í•´ì•¼ í•©ë‹ˆë‹¤: modeldata, ranger, and tidymodels.


```r
library(tidymodels) # for the rsample package, along with the rest of tidymodels

# Helper packages
library(modeldata)  # for the cells data
```

{{< test-drive url="https://rstudio.cloud/project/2674862" >}}

## ì„¸í¬ ì´ë¯¸ì§€ ë°ì´í„° {#data}

[modeldata íŒ¨í‚¤ì§€](https://cran.r-project.org/web/packages/modeldata/index.html) ì— ìˆëŠ” [Hill, LaPan, Li, and Haney (2007)](http://www.biomedcentral.com/1471-2105/8/340) ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬, resampling ìœ¼ë¡œ ì„¸í¬ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆì„ ì˜ˆì¸¡í•´ ë´…ì‹œë‹¤. ì´ ë°ì´í„°ë¥¼ R ì— ë¡œë“œí•©ë‹ˆë‹¤:


```r
data(cells, package = "modeldata")
cells
#> # A tibble: 2,019 Ã— 58
#>   case  class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3
#>   <fct> <fct>      <dbl>     <int>          <dbl>          <dbl>          <dbl>
#> 1 Test  PS        143.         185           15.7           4.95           9.55
#> 2 Train PS        134.         819           31.9         207.            69.9 
#> 3 Train WS        107.         431           28.0         116.            63.9 
#> 4 Train PS         69.2        298           19.5         102.            28.2 
#> 5 Test  PS          2.89       285           24.3         112.            20.5 
#> # â€¦ with 2,014 more rows, and 51 more variables: avg_inten_ch_4 <dbl>,
#> #   convex_hull_area_ratio_ch_1 <dbl>, convex_hull_perim_ratio_ch_1 <dbl>,
#> #   diff_inten_density_ch_1 <dbl>, diff_inten_density_ch_3 <dbl>, â€¦
```

2019 ê°œì˜ ì„¸í¬ì™€ 58 ê°œì˜ ë³€ìˆ˜ê°€ ìˆëŠ” ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ìš°ë¦¬ê°€ ê´€ì‹¬ìˆëŠ” ì£¼ ë°˜ì‘ë³€ìˆ˜ëŠ” `class` ì¸ë°, íŒ©í„°í˜•ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ `class` ë³€ìˆ˜ ì˜ˆì¸¡ì„ ì‹œì‘í•˜ê¸°ì— ì•ì„œ ì´ ë³€ìˆ˜ì— ëŒ€í•´ ë” ì´í•´í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì„¸í¬ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì— ëŒ€í•œ ê°„ëµí•œ ì„œë¬¸ì…ë‹ˆë‹¤.

### ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ ì˜ˆì¸¡í•˜ê¸°

ì„¸í¬ ì‹¤í—˜ì„ í•˜ëŠ” ìƒë¬¼í•™ìë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì œì•½ë¶„ì•¼ì—ì„œ íŠ¹ì •ìœ í˜•ì˜ ì„¸í¬ê°€ ì•½ì´ë‚˜ ëŒ€ì¡°êµ° ìœ¼ë¡œ ì·¨ê¸‰í•œ í›„ (ë‚˜íƒ€ë‚˜ê²Œ ë ) íš¨ê³¼ë¥¼ ê´€ì¸¡í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¢…ë¥˜ì˜ ì¸¡ì •ì— ìˆì–´ ë³´í†µì˜ ë°©ë²•ì€ ì„¸í¬ ì´ë¯¸ì§•ì…ë‹ˆë‹¤. ì„¸í¬ì˜ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì´ ìƒ‰ì¹ ì´ ì¹ í•´ì ¸ì„œ ì„¸í¬ì˜ ìœ„ì¹˜ê°€ ê²°ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ë“¤ì–´, ì„¸í¬ ë‹¤ì„¯ê°œê°€ ìˆëŠ” ì´ë¯¸ì§€ì˜ ìœ„ íŒ¨ë„ì—ì„œ ë…¹ìƒ‰ì€ ì„¸í¬ ê²½ê³„ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ (cytoskeleton ì´ë¼ê³  í•˜ëŠ” ì—¼ìƒ‰) ì²­ìƒ‰ì€ ì„¸í¬ í•µì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

<img src="img/cells.png" width="70%" style="display: block; margin: auto;" />

ì´ëŸ¬í•œ ìƒ‰ê¹”ì„ ì´ìš©í•´ì„œ ì´ë¯¸ì§€ ì•ˆì˜ ì„¸í¬ëŠ” _ê²½ê³„ë¥¼ ì¡ì•„ (segmented)_ ì„œ ì–´ë–¤ í”½ì…€ì´ ì–´ë–¤ ì„¸í¬ì— ì†í•˜ëŠ”ì§€ ì•Œì•„ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì´ ì˜ ëœë‹¤ë©´, ì„¸í¬ê°€ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì¸¡ì •ì´ ë˜ì–´ ìƒë¬¼í•™ ì—°êµ¬ì— ìˆì–´ ì¤‘ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸í¬ ëª¨ì–‘ì´ ì¤‘ìš”í•œ ê²½ìš°ê°€ ìˆì–´ í¬ê¸°ë‚˜ "ì¥ë°©í˜•" ê°™ì€ íŠ¹ì§•ë“¤ì„ ìš”ì•½í•˜ëŠ”ë° ë‹¤ì–‘í•œ ìˆ˜í•™ì  ë„êµ¬ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. 

ì•„ë˜ íŒ¨ë„ì€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. 1ë²ˆê³¼ 5ë²ˆ ì„¸í¬ëŠ” ê½¤ ì˜ ì„¸ê·¸ë©˜íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, 3ë²ˆ 4ë²ˆ ì„¸í¬ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ ì˜ ë˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ë­‰ì³ì ¸ ìˆìŠµë‹ˆë‹¤. ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ ì˜ ë˜ì§€ ì•Šìœ¼ë©´, ë°ì´í„° ì˜¤ì—¼ì´ ë©ë‹ˆë‹¤; ìƒë¬¼í•™ìëŠ” ì´ëŸ¬í•œ ì„¸í¬ì˜ ëª¨ì–‘ì´ë‚˜ í¬ê¸°ë¥¼ ë¶„ì„í•  ë•Œ, ë°ì´í„°ê°€ ì •í™•í•˜ì§€ ì•Šê³  ì˜ëª»ëœ ê²°ë¡ ì„ ë„ì¶œí•˜ê²Œ ë©ë‹ˆë‹¤.  

ì„¸í¬ ê¸°ë°˜ ì‹¤í—˜ì€ ìˆ˜ë°±ë§Œ ì„¸í¬ë¥¼ ë‹¤ë£¨ë¯€ë¡œ ì´ë“¤ì„ ëª¨ë‘ ì‹œê°ì ìœ¼ë¡œ ì‚´í´ë³´ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ëŒ€ì‹ , ì„œë¸Œìƒ˜í”Œì„ ìƒì„±í•˜ì—¬ ì „ë¬¸ê°€ê°€ ì˜ëª» ì„¸ê·¸ë©˜íŠ¸ë¨ (`PS`), ì˜ ì„¸ê·¸ë©˜íŠ¸ë¨ (`WS`) ì¤‘ í•˜ë‚˜ë¡œ ìˆ˜ë™ìœ¼ë¡œ ë¼ë²¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¼ë²¨ì„ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìœ¼ë©´, ì˜ëª» ì„¸ê·¸ë©˜íŠ¸ëœ ê²ƒ ê°™ì€ ì„¸í¬ë“¤ì„ í•„í„°ë§í•˜ì—¬ ëŒ€ëŸ‰ì˜ ë°ì´í„°ê°€ ê°œì„ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

### ì„¸í¬ ë°ì´í„° ëŒì•„ê°€ê¸°

`cells` ë°ì´í„°ì—ëŠ” 2019 ì„¸í¬ì˜ `class` ë¼ë²¨ì´ ìˆìŠµë‹ˆë‹¤ &mdash; ê° ì„¸í¬ëŠ” ì˜ëª» ì„¸ê·¸ë©˜íŠ¸ë¨ (`PS`), ì˜ ì„¸ê·¸ë©˜íŠ¸ë¨ (`WS`) ì¤‘ í•˜ë‚˜ë¡œ ë¼ë²¨ë§ ë©ë‹ˆë‹¤. ê° ì„¸í¬ëŠ” ìë™ ì´ë¯¸ì§€ ë¶„ì„ ì¸¡ì •ê°’ë“¤ì— ê¸°ë°˜í•˜ì—¬ ì´ 56 ê°œì˜ ì„¤ëª…ë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `avg_inten_ch_1` ëŠ” í•µì— í¬í•¨ëœ ë°ì´í„°ì˜ í‰ê· ê°•ë„ì´ê³ , `area_ch_1` ì€ ì„¸í¬ì˜ ì´ í¬ê¸°, ë“±ì…ë‹ˆë‹¤. (ëª‡ëª‡ ì„¤ëª…ë³€ìˆ˜ëŠ” ì˜ë¯¸ê°€ íŒŒì•…ì´ ì•ˆë¨)


```r
cells
#> # A tibble: 2,019 Ã— 58
#>   case  class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3
#>   <fct> <fct>      <dbl>     <int>          <dbl>          <dbl>          <dbl>
#> 1 Test  PS        143.         185           15.7           4.95           9.55
#> 2 Train PS        134.         819           31.9         207.            69.9 
#> 3 Train WS        107.         431           28.0         116.            63.9 
#> 4 Train PS         69.2        298           19.5         102.            28.2 
#> 5 Test  PS          2.89       285           24.3         112.            20.5 
#> # â€¦ with 2,014 more rows, and 51 more variables: avg_inten_ch_4 <dbl>,
#> #   convex_hull_area_ratio_ch_1 <dbl>, convex_hull_perim_ratio_ch_1 <dbl>,
#> #   diff_inten_density_ch_1 <dbl>, diff_inten_density_ch_3 <dbl>, â€¦
```

í´ë˜ìŠ¤ë“¤ì˜ ë¹„ìœ¨ì€ ë‹¤ì†Œ ë¶ˆê· í˜•ì…ë‹ˆë‹¤; ì˜ ì„¸ê·¸ë©˜íŠ¸ëœ ì„¸í¬ë“¤ë³´ë‹¤ ì˜ëª» ì„¸ê·¸ë©˜íŠ¸ëœ ì„¸í¬ë“¤ì´ ë” ë§ìŠµë‹ˆë‹¤. 


```r
cells %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))
#> # A tibble: 2 Ã— 3
#>   class     n  prop
#>   <fct> <int> <dbl>
#> 1 PS     1300 0.644
#> 2 WS      719 0.356
```

## ë°ì´í„° ë‚˜ëˆ„ê¸° {#data-split}

ì´ì „ì˜ [*recipe ë¡œ ë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸°*](/start/recipes/#data-split) ì¥ì—ì„œ ë°ì´í„° ë‚˜ëˆ„ê¸° ë¶€í„° ì‹œì‘í–ˆì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ë§ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•  ë•Œ, ë³´í†µ [ë°ì´í„°ì…‹ì„ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë¶„ë¦¬](https://bookdown.org/max/FES/data-splitting.html)ë¶€í„° í•©ë‹ˆë‹¤: 

 * _íŠ¸ë ˆì´ë‹ì…‹_ ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì •í•˜ê³ , ëª¨ë¸ê³¼ í”¼ì³ì—”ì§€ë‹ˆì–´ë§ ê¸°ìˆ ì„ ë¹„êµí•˜ê³ , ëª¨ë¸ì„ íŠœë‹í•˜ëŠ” ë“±ì— ì´ìš©ë©ë‹ˆë‹¤.

 * _í…ŒìŠ¤íŠ¸ì…‹_ ì€ í”„ë¡œì íŠ¸ ë§ˆì§€ë§‰ì— ì‚¬ìš©ë˜ëŠ”ë°, ì´ ì‹œì ì—ì„œëŠ” ì‹¬ê°í•˜ê²Œ ê³ ë ¤í•˜ëŠ” ëª¨ë¸ì´ í•œê°œë‚˜ ë‘ê°œ ì •ë„ì—¬ì•¼ í•©ë‹ˆë‹¤. ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ì¸¡ì •ì„ ìœ„í•œ unbiased source ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

ë°ì´í„°ë¥¼ ì´ë ‡ê²Œ ë‚˜ëˆ„ëŠ” ë²•ì€ ì—¬ëŸ¬ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ ëœë¤ìƒ˜í”Œì„ ì´ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì´í„° ì‚¬ë¶„ì˜ ì¼ì´ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë¶„ë¦¬ë˜ì—ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ëœë¤ìƒ˜í”Œë§ì€ 25% ë¥¼ ëœë¤í•˜ê²Œ ì„ íƒí•˜ì—¬ í…ŒìŠ¤íŠ¸ì…‹ì„ ë§Œë“¤ê³ , ë‚˜ë¨¸ì§€ë¥¼ íŠ¸ë ˆì´ë‹ì…‹ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. [rsample](https://tidymodels.github.io/rsample/) íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë ‡ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ëœë¤ ìƒ˜í”Œë§ì€ ëœë¤ë„˜ë²„ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ëœë¤ë„˜ë²„ ì”¨ë“œë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ëœë¤ë„˜ë²„ëŠ” (í•„ìš”ì‹œ) ë‚˜ì¤‘ì— ëœë¤ë„˜ë²„ë¥¼ ì¬í˜„í•  ìˆ˜ ìˆê²Œ í•´ ì¤ë‹ˆë‹¤. 

í•¨ìˆ˜ `rsample::initial_split()` ì€ ì›ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ, ì–´ë–»ê²Œ ë¶„ë¦¬í•˜ëŠ” ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ì› ë¶„ì„ì—ì„œ, ì €ìë“¤ì€ ìì‹ ë“¤ë§Œì˜ íŠ¸ë ˆì´ë‹/í…ŒìŠ¤íŠ¸ì…‹ì„ ë§Œë“¤ì—ˆê³ , ì´ ì •ë³´ëŠ” `case`ì—´ì— ì €ì¥ë©ë‹ˆë‹¤. ë‚˜ëˆˆ ë°©ë²•ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´, ìš°ë¦¬ë§Œì˜ ë¶„ë¦¬ë¥¼ í•˜ê¸° ì „ì— ì´ ì—´ì„ ì œê±°í•  ê²ƒì…ë‹ˆë‹¤:


```r
set.seed(123)
cell_split <- initial_split(cells %>% select(-case), 
                            strata = class)
```

ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” [`strata` ì¸ìˆ˜](https://tidymodels.github.io/rsample/reference/initial_split.html) ë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, ì´ëŠ” ì¸µí™”ë¶„ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš°ë¦¬ `class` ë³€ìˆ˜ì—ì„œ ë°œê²¬í•œ ë¶ˆê· í˜•ì—ë„ ë¶ˆêµ¬í•˜ê³  ìš°ë¦¬ íŠ¸ë ˆì´ë‹ê³¼ í…ŒìŠ¤íŠ¸ì…‹ì€ ì˜ëª» ì„¸ê·¸ë©˜íŠ¸, ì˜ ì„¸ê·¸ë©˜íŠ¸ëœ ì„¸í¬ì˜ ë¹„ìœ¨ì„ ì›ë°ì´í„°ì™€ ëŒ€ëµ ê°™ê²Œ ìœ ì§€í•˜ê²Œ í•´ ì¤ë‹ˆë‹¤. `initial_split` ì„ í•œ í›„ `training()` ê³¼ `testing()` í•¨ìˆ˜ë“¤ì€ ì‹¤ì œ ë°ì´í„°ì…‹ì„ ë°˜í™˜í•©ë‹ˆë‹¤.


```r
cell_train <- training(cell_split)
cell_test  <- testing(cell_split)

nrow(cell_train)
#> [1] 1514
nrow(cell_train)/nrow(cells)
#> [1] 0.7498762

# training set proportions by class
cell_train %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))
#> # A tibble: 2 Ã— 3
#>   class     n  prop
#>   <fct> <int> <dbl>
#> 1 PS      975 0.644
#> 2 WS      539 0.356

# test set proportions by class
cell_test %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))
#> # A tibble: 2 Ã— 3
#>   class     n  prop
#>   <fct> <int> <dbl>
#> 1 PS      325 0.644
#> 2 WS      180 0.356
```

ì´í›„ íŠ¸ë ˆì´ë‹ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ë§ ì‘ì—…ì˜ ëŒ€ë¶€ë¶„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.


## ëª¨ë¸ë§

[ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸](https://en.wikipedia.org/wiki/Random_forest) ì€ [decision tree](https://en.wikipedia.org/wiki/Decision_tree) ì˜  [ì•™ìƒë¸”](https://en.wikipedia.org/wiki/Ensemble_learning) ì…ë‹ˆë‹¤. ì•½ê°„ ë‹¤ë¥¸ íŠ¸ë ˆì´ë‹ ì…‹ì— ê¸°ë°˜í•˜ì—¬ ë§ì€ ìˆ˜ì˜ decision tree ëª¨ë¸ì´ ìƒì„±ë©ë‹ˆë‹¤. ê° decision tree ê°€ ìƒì„±ë  ë•Œ, ì í•©ê³¼ì •ì€ ìµœëŒ€í•œ decision tree ë“¤ì´ ë‹¤ì–‘í•˜ê²Œ ë˜ê¸¸ ìœ ë„í•©ë‹ˆë‹¤. íŠ¸ë¦¬ì˜ ì§‘í•©ì€ ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ë¡œ ì¡°í•©ë˜ê³ , ìƒˆë¡œìš´ ìƒ˜í”Œì´ ì˜ˆì¸¡ë  ë•Œ, ê° íŠ¸ë¦¬ë¡œ ë¶€í„°ì˜ íˆ¬í‘œê°€ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ìš°ë¦¬ì˜ `cells` ì˜ˆì‹œ ë°ì´í„°ì˜ `class` ì™€ ê°™ì€ ë²”ì£¼í˜• ì¢…ì†ë³€ìˆ˜ì— ëŒ€í•´, ëœë¤í¬ë ˆìŠ¤íŠ¸ì˜ ëª¨ë“  íŠ¸ë¦¬ë¥¼ í†µí‹€ì–´ ê°€ì¥ ë§ì€ íˆ¬í‘œë¥¼ ë°›ì€ ëª¨ë¸ì´ ìƒˆë¡œìš´ ìƒ˜í”Œì˜ ì˜ˆì¸¡ ë²”ì£¼ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. 

ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì˜ ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ìœ ì§€ì— ì†ì´ ê±°ì˜ ë“¤ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•  í•„ìš”ê°€ ê±°ì˜ ì—†ê³ , ê¸°ë³¸ê°’ íŒŒë¼ë¯¸í„°ë“¤ì´ ê´œì°®ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ìš°ë¦¬ëŠ” `cells` ë°ì´í„°ë¥¼ ìœ„í•´ ë ˆì‹œí”¼ë¥¼ ìƒì„±í•˜ì§€ëŠ” ì•Šì„ ê²ƒì…ë‹ˆë‹¤. 

ë™ì‹œì—, ë Œë¤í¬ë ˆìŠ¤íŠ¸ë¼ëŠ” ì´ ì•™ìƒë¸” ëª¨ë¸ì˜ ë‚˜ë¬´ ê°œìˆ˜ëŠ” ì»¤ì•¼í•˜ê³  (ìˆ˜ì²œ), ì´ë¡œ ì¸í•´ ëª¨ë¸ì„ ê³„ì‚°í•˜ëŠ”ë° ê½¤ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.

[parsnip](https://tidymodels.github.io/parsnip/) íŒ¨í‚¤ì§€ë¥¼ [ranger](https://cran.r-project.org/web/packages/ranger/index.html) ì—”ì§„ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ ì í•©í•´ ë´…ì‹œë‹¤. ìš°ë¦¬ê°€ ìƒì„±í•˜ê³  ì‹¶ì€ ëª¨ë¸ì„ ìš°ì„  ì •ì˜í•©ë‹ˆë‹¤:


```r
rf_mod <- 
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")
```

ìœ„ì˜ parsnip ëª¨ë¸ ê°ì²´ë¶€í„° ì‹œì‘í•˜ì—¬ `fit()` í•¨ìˆ˜ëŠ” ëª¨ë¸ ê³µì‹ê³¼ í•¨ê»˜ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ ëœë¤ ë„˜ë²„ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ê³„ì‚°ì— ì•ì„œ ì‹œë“œë¥¼ í•œë²ˆë” ì„¤ì •í•©ë‹ˆë‹¤: 


```r
set.seed(234)
rf_fit <- 
  rf_mod %>% 
  fit(class ~ ., data = cell_train)
rf_fit
#> parsnip model object
#> 
#> Fit time:  2.3s 
#> Ranger result
#> 
#> Call:
#>  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) 
#> 
#> Type:                             Probability estimation 
#> Number of trees:                  1000 
#> Sample size:                      1514 
#> Number of independent variables:  56 
#> Mtry:                             7 
#> Target node size:                 10 
#> Variable importance mode:         none 
#> Splitrule:                        gini 
#> OOB prediction error (Brier s.):  0.1189338
```

ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ì§„ `rf_fit` ê°ì²´ëŠ” íŠ¸ë ˆì´ë‹ ë°ì´í„°ì…‹ì—ì„œ íŠ¸ë ˆì´ë‹ëœ ì í•©ëœ ëª¨ë¸ì…ë‹ˆë‹¤. 


## ì„±ëŠ¥ ì¶”ì •í•˜ê¸° {#performance}

ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ë™ì•ˆ, ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë“¤ ì¤‘ ì„ íƒí•˜ê¸° ìœ„í•´ ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ì–¼ë§ˆë‚˜ ì˜ ë˜ëŠ”ì§€, ì„±ëŠ¥ í†µê³„ëŸ‰ë“¤ì„ ì¸¡ì •í•˜ì—¬ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì¥ì˜ ì˜ˆì—ì„œ, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì„ íƒì§€ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

 * the area under the Receiver Operating Characteristic (ROC) curve
 
 * ì¢…í•© ë¶„ë¥˜ ì •í™•ë„ (accuracy).
 
ROC ì»¤ë¸ŒëŠ” í´ë˜ìŠ¤ í™•ë¥  ì¶”ì •ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì ì¬ í™•ë¥  ì»·ì˜¤í”„ì˜ ì „ì²´ì…‹ì„ í†µí•´ ì„±ëŠ¥ ê°ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Hard class ì˜ˆì¸¡ê°’ì€ ê° ì„¸í¬ë§ˆë‹¤ `PS`, `WS` ë¥¼ ì˜ˆì¸¡í–ˆëŠ”ì§€ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ì˜ˆì¸¡ ë’¤ì—, ëª¨ë¸ì€ í™•ë¥ ì„ ì‚¬ì‹¤ì„ ì¸¡ì •í•©ë‹ˆë‹¤. 50% í™•ë¥  ì»·ì˜¤í”„ê°€ ìã…ã„¹ëª» ì„¸ê·¸ë©˜íŠ¸ëœ ê²ƒìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. 

[yardstick íŒ¨í‚¤ì§€](https://tidymodels.github.io/yardstick/) ì—ëŠ” ì´ëŸ¬í•œ ë‘ ì¸¡ì •ê°’ë“¤ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜, `roc_auc()` ì™€ `accuracy()` ê°€ ìˆìŠµë‹ˆë‹¤. 

ì²˜ìŒ ë³´ì•„ì„œëŠ” ì´ëŸ¬í•œ í†µê³„ëŸ‰ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ íŠ¸ë ˆì´ë‹ ì…‹ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì•„ ë³´ì…ë‹ˆë‹¤. (ì´ëŠ” ì‚¬ì‹¤ ë§¤ìš° ë‚˜ìœ ìƒê°ì…ë‹ˆë‹¤.) ì´ë ‡ê²Œ í–ˆì„ë•Œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤. íŠ¸ë ˆì´ë‹ì…‹ì— ê¸°ë°˜í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ `predict()` ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ë‘ ì¢…ë¥˜ì˜ ì˜ˆì¸¡ (ì¦‰, í™•ë¥ ê³¼ hard class ì˜ˆì¸¡) ì„ êµ¬í•©ë‹ˆë‹¤. 


```r
rf_training_pred <- 
  predict(rf_fit, cell_train) %>% 
  bind_cols(predict(rf_fit, cell_train, type = "prob")) %>% 
  # Add the true outcome data back in
  bind_cols(cell_train %>% 
              select(class))
```

yardstick í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ì—¬, ì´ ëª¨ë¸ì€ ì—„ì²­ë‚œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ”ë°, ê²°ê³¼ê°€ ë„ˆë¬´ ì—„ì²­ë‚˜ì„œ ì˜ì‹¬ì´ ìƒê¸°ê¸° ì‹œì‘í•  ê²ƒì…ë‹ˆë‹¤: 


```r
rf_training_pred %>%                # training set predictions
  roc_auc(truth = class, .pred_PS)
#> # A tibble: 1 Ã— 3
#>   .metric .estimator .estimate
#>   <chr>   <chr>          <dbl>
#> 1 roc_auc binary          1.00
rf_training_pred %>%                # training set predictions
  accuracy(truth = class, .pred_class)
#> # A tibble: 1 Ã— 3
#>   .metric  .estimator .estimate
#>   <chr>    <chr>          <dbl>
#> 1 accuracy binary         0.991
```

ì´ ëª¨ë¸ì´ ë§¤ìš° ì„±ëŠ¥ì´ ì¢‹ê¸° ë•Œë¬¸ì—, í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ìš°ë¦¬ ê²°ê³¼ê°€ ë‚˜ì˜ì§€ëŠ” ì•Šì§€ë§Œ, íŠ¸ë ˆì´ë‹ì…‹ ì˜ˆì¸¡ì‘ì—…ì— ê¸°ë°˜í•˜ì—¬ ì²˜ìŒ ê¸°ëŒ€í–ˆë˜ ê²ƒ ë³´ë‹¤ í›¨ì”¬ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤.


```r
rf_testing_pred <- 
  predict(rf_fit, cell_test) %>% 
  bind_cols(predict(rf_fit, cell_test, type = "prob")) %>% 
  bind_cols(cell_test %>% select(class))
```


```r
rf_testing_pred %>%                   # test set predictions
  roc_auc(truth = class, .pred_PS)
#> # A tibble: 1 Ã— 3
#>   .metric .estimator .estimate
#>   <chr>   <chr>          <dbl>
#> 1 roc_auc binary         0.891
rf_testing_pred %>%                   # test set predictions
  accuracy(truth = class, .pred_class)
#> # A tibble: 1 Ã— 3
#>   .metric  .estimator .estimate
#>   <chr>    <chr>          <dbl>
#> 1 accuracy binary         0.816
```

### ë¬´ìŠ¨ì¼ì´ ì¼ì–´ë‚œ ê±°ì•¼?

ì´ ì„¹ì…˜ì—ì„œ ë³´ì´ëŠ” ê²ƒ ê°™ì´ íŠ¸ë ˆì´ë‹ì…‹ í†µê³„ëŸ‰ì´ ì‹¤ì œì™€ ë‹¤ë¥´ê²Œ ê¸ì •ì ì¸ ê²ƒì—ì„œëŠ” ì—¬ëŸ¬ ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤. 

* ëœë¤í¬ë ˆìŠ¤íŠ¸, ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬, ë‹¤ë¥¸ ë¸”ë™ë°•ìŠ¤ ë°©ë²•ë“¤ ê°™ì€ ëª¨ë¸ë“¤ì€ íŠ¸ë ˆì´ë‹ì…‹ì„ ë³¸ì§ˆì ìœ¼ë¡œ ì•”ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°™ì€ ì…‹ì„ ë‹¤ì‹œ ì˜ˆì¸¡í•˜ë©´ í•­ìƒ ê±°ì˜ ì™„ë²½í•œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ë°–ì— ì—†ë‹¤. 
ê°•ì˜ 
* The training set does not have the capacity to be a good arbiter of performance. It is not an independent piece of information; predicting the training set can only reflect what the model already knows. 

To understand that second point better, think about an analogy from teaching. Suppose you give a class a test, then give them the answers, then provide the same test. The student scores on the _second_ test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test. 



## Resampling ë¥¼ ì´ìš©í•œ ë¬¸ì œí•´ê²° {#resampling}

cross-validation ê³¼ bootstrap ê³¼ ê°™ì€ resampling ë°©ë²•ì€ ì‹¤í—˜ì  ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ë“¤ì€ ì´ì „ì— ë…¼ì˜í•œ training/testing ë¶„í• ê³¼ ìœ ì‚¬í•˜ê²Œ ë°ì´í„°ì…‹ ì¼ë ¨ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì˜ ì„œë¸Œì…‹ì€ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©ë˜ê³  ë‹¤ë¥¸ ì„œë¸Œì…‹ì€ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ë¦¬ìƒ˜í”Œë§ì€ í•­ìƒ _íŠ¸ë ˆì´ë‹ì…‹_ ê³¼ ì‚¬ìš©ë©ë‹ˆë‹¤. [Kuhn and Johnson (2019)](https://bookdown.org/max/FES/resampling.html) ì˜ ìŠ¤ì¼€ë§¤í‹±ì—ì„œ ë¦¬ìƒ˜í”Œë§ ë©”ì†Œë“œì˜ ë°ì´í„° ì‚¬ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

<img src="img/resampling.svg" width="85%" style="display: block; margin: auto;" />

ì´ ë‹¤ì´ì–´ê·¸ë¨ì˜ ì²«ë²ˆì§¸ ìˆ˜ì¤€ì—ì„œ, `rsample::initial_split()` ì„ ì‚¬ìš©í•  ë•Œ ì¼ì–´ë‚˜ëŠ” ì¼ì„ ë³¼ ìˆ˜ ìˆëŠ”ë°, ì› ë°ì´í„°ë¥¼ íŠ¸ë ˆì´ë‹ê³¼ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤. ê·¸ í›„ íŠ¸ë ˆì´ë‹ì…‹ì´ ë¦¬ìƒ˜í”Œë§ì„ ìœ„í•´ ì„ íƒë˜ê³  í…ŒìŠ¤íŠ¸ì…‹ì€ ë³´ì¡´ë©ë‹ˆë‹¤.

ì´ ì˜ˆì—ì„œ 10-í´ë“œ cross-validation (CV) ë¥¼ ì˜¤
Let's use 10-fold cross-validation (CV) in this example. This method randomly allocates the 1514 cells in the training set to 10 groups of roughly equal size, called "folds". For the first iteration of resampling, the first fold of about 151 cells are held out for the purpose of measuring performance. This is similar to a test set but, to avoid confusion, we call these data the _assessment set_ in the tidymodels framework. 

The other 90% of the data (about 1362 cells) are used to fit the model. Again, this sounds similar to a training set, so in tidymodels we call this data the _analysis set_. This model, trained on the analysis set, is applied to the assessment set to generate predictions, and performance statistics are computed based on those predictions. 

In this example, 10-fold CV moves iteratively through the folds and leaves a different 10% out each time for model assessment. At the end of this process, there are 10 sets of performance statistics that were created on 10 data sets that were not used in the modeling process. For the cell example, this means 10 accuracies and 10 areas under the ROC curve. While 10 models were created, these are not used further; we do not keep the models themselves trained on these folds because their only purpose is calculating performance metrics. 



The final resampling estimates for the model are the **averages** of the performance statistics replicates. For example, suppose for our data the results were: 

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> resample </th>
   <th style="text-align:right;"> accuracy </th>
   <th style="text-align:right;"> roc_auc </th>
   <th style="text-align:right;"> assessment size </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Fold01 </td>
   <td style="text-align:right;"> 0.8289474 </td>
   <td style="text-align:right;"> 0.8937128 </td>
   <td style="text-align:right;"> 152 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold02 </td>
   <td style="text-align:right;"> 0.7697368 </td>
   <td style="text-align:right;"> 0.8768989 </td>
   <td style="text-align:right;"> 152 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold03 </td>
   <td style="text-align:right;"> 0.8552632 </td>
   <td style="text-align:right;"> 0.9017666 </td>
   <td style="text-align:right;"> 152 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold04 </td>
   <td style="text-align:right;"> 0.8552632 </td>
   <td style="text-align:right;"> 0.8928076 </td>
   <td style="text-align:right;"> 152 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold05 </td>
   <td style="text-align:right;"> 0.7947020 </td>
   <td style="text-align:right;"> 0.8816342 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold06 </td>
   <td style="text-align:right;"> 0.8476821 </td>
   <td style="text-align:right;"> 0.9244306 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold07 </td>
   <td style="text-align:right;"> 0.8145695 </td>
   <td style="text-align:right;"> 0.8960339 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold08 </td>
   <td style="text-align:right;"> 0.8543046 </td>
   <td style="text-align:right;"> 0.9267677 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold09 </td>
   <td style="text-align:right;"> 0.8543046 </td>
   <td style="text-align:right;"> 0.9231392 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Fold10 </td>
   <td style="text-align:right;"> 0.8476821 </td>
   <td style="text-align:right;"> 0.9266917 </td>
   <td style="text-align:right;"> 151 </td>
  </tr>
</tbody>
</table>

From these resampling statistics, the final estimate of performance for this random forest model would be 0.904 for the area under the ROC curve and 0.832 for accuracy. 

These resampling statistics are an effective method for measuring model performance _without_ predicting the training set directly as a whole. 

## Fit a model with resampling {#fit-resamples}

To generate these results, the first step is to create a resampling object using rsample. There are [several resampling methods](https://tidymodels.github.io/rsample/reference/index.html#section-resampling-methods) implemented in rsample; cross-validation folds can be created using `vfold_cv()`: 


```r
set.seed(345)
folds <- vfold_cv(cell_train, v = 10)
folds
#> #  10-fold cross-validation 
#> # A tibble: 10 Ã— 2
#>    splits             id    
#>    <list>             <chr> 
#>  1 <split [1362/152]> Fold01
#>  2 <split [1362/152]> Fold02
#>  3 <split [1362/152]> Fold03
#>  4 <split [1362/152]> Fold04
#>  5 <split [1363/151]> Fold05
#>  6 <split [1363/151]> Fold06
#>  7 <split [1363/151]> Fold07
#>  8 <split [1363/151]> Fold08
#>  9 <split [1363/151]> Fold09
#> 10 <split [1363/151]> Fold10
```

The list column for `splits` contains the information on which rows belong in the analysis and assessment sets. There are functions that can be used to extract the individual resampled data called `analysis()` and `assessment()`. 

However, the tune package contains high-level functions that can do the required computations to resample a model for the purpose of measuring performance. You have several options for building an object for resampling:

+ Resample a model specification preprocessed with a formula or [recipe](/start/recipes/), or 

+ Resample a [`workflow()`](https://tidymodels.github.io/workflows/) that bundles together a model specification and formula/recipe. 

For this example, let's use a `workflow()` that bundles together the random forest model and a formula, since we are not using a recipe. Whichever of these options you use, the syntax to `fit_resamples()` is very similar to `fit()`: 


```r
rf_wf <- 
  workflow() %>%
  add_model(rf_mod) %>%
  add_formula(class ~ .)

set.seed(456)
rf_fit_rs <- 
  rf_wf %>% 
  fit_resamples(folds)
```


```r
rf_fit_rs
#> # Resampling results
#> # 10-fold cross-validation 
#> # A tibble: 10 Ã— 4
#>    splits             id     .metrics         .notes          
#>    <list>             <chr>  <list>           <list>          
#>  1 <split [1362/152]> Fold01 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  2 <split [1362/152]> Fold02 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  3 <split [1362/152]> Fold03 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  4 <split [1362/152]> Fold04 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  5 <split [1363/151]> Fold05 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  6 <split [1363/151]> Fold06 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  7 <split [1363/151]> Fold07 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  8 <split [1363/151]> Fold08 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#>  9 <split [1363/151]> Fold09 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
#> 10 <split [1363/151]> Fold10 <tibble [2 Ã— 4]> <tibble [0 Ã— 1]>
```

The results are similar to the `folds` results with some extra columns. The column `.metrics` contains the performance statistics created from the 10 assessment sets. These can be manually unnested but the tune package contains a number of simple functions that can extract these data: 
 

```r
collect_metrics(rf_fit_rs)
#> # A tibble: 2 Ã— 6
#>   .metric  .estimator  mean     n std_err .config             
#>   <chr>    <chr>      <dbl> <int>   <dbl> <chr>               
#> 1 accuracy binary     0.832    10 0.00952 Preprocessor1_Model1
#> 2 roc_auc  binary     0.904    10 0.00610 Preprocessor1_Model1
```

Think about these values we now have for accuracy and AUC. These performance metrics are now more realistic (i.e. lower) than our ill-advised first attempt at computing performance metrics in the section above. If we wanted to try different model types for this data set, we could more confidently compare performance metrics computed using resampling to choose between models. Also, remember that at the end of our project, we return to our test set to estimate final model performance. We have looked at this once already before we started using resampling, but let's remind ourselves of the results:


```r
rf_testing_pred %>%                   # test set predictions
  roc_auc(truth = class, .pred_PS)
#> # A tibble: 1 Ã— 3
#>   .metric .estimator .estimate
#>   <chr>   <chr>          <dbl>
#> 1 roc_auc binary         0.891
rf_testing_pred %>%                   # test set predictions
  accuracy(truth = class, .pred_class)
#> # A tibble: 1 Ã— 3
#>   .metric  .estimator .estimate
#>   <chr>    <chr>          <dbl>
#> 1 accuracy binary         0.816
```

The performance metrics from the test set are much closer to the performance metrics computed using resampling than our first ("bad idea") attempt. Resampling allows us to simulate how well our model will perform on new data, and the test set acts as the final, unbiased check for our model's performance.



## Session information


```
#> â”€ Session info  ğŸŒ’  ğŸ’‘  ğŸ‡³ğŸ‡±   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#>  hash: waxing crescent moon, couple with heart, flag: Netherlands
#> 
#>  setting  value
#>  version  R version 4.1.1 (2021-08-10)
#>  os       macOS Big Sur 10.16
#>  system   x86_64, darwin17.0
#>  ui       X11
#>  language (EN)
#>  collate  en_US.UTF-8
#>  ctype    en_US.UTF-8
#>  tz       Asia/Seoul
#>  date     2021-12-20
#>  pandoc   2.11.4 @ /Applications/RStudio.app/Contents/MacOS/pandoc/ (via rmarkdown)
#> 
#> â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#>  package    * version date (UTC) lib source
#>  broom      * 0.7.10  2021-10-31 [1] CRAN (R 4.1.0)
#>  dials      * 0.0.10  2021-09-10 [1] CRAN (R 4.1.0)
#>  dplyr      * 1.0.7   2021-06-18 [1] CRAN (R 4.1.0)
#>  ggplot2    * 3.3.5   2021-06-25 [1] CRAN (R 4.1.0)
#>  infer      * 1.0.0   2021-08-13 [1] CRAN (R 4.1.0)
#>  modeldata  * 0.1.1   2021-07-14 [1] CRAN (R 4.1.0)
#>  parsnip    * 0.1.7   2021-07-21 [1] CRAN (R 4.1.0)
#>  purrr      * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)
#>  ranger     * 0.13.1  2021-07-14 [1] CRAN (R 4.1.0)
#>  recipes    * 0.1.17  2021-09-27 [1] CRAN (R 4.1.0)
#>  rlang      * 0.4.12  2021-10-18 [1] CRAN (R 4.1.0)
#>  rsample    * 0.1.1   2021-11-08 [1] CRAN (R 4.1.0)
#>  tibble     * 3.1.6   2021-11-07 [1] CRAN (R 4.1.0)
#>  tidymodels * 0.1.4   2021-10-01 [1] CRAN (R 4.1.0)
#>  tune       * 0.1.6   2021-07-21 [1] CRAN (R 4.1.0)
#>  workflows  * 0.2.4   2021-10-12 [1] CRAN (R 4.1.0)
#>  yardstick  * 0.0.9   2021-11-22 [1] CRAN (R 4.1.0)
#> 
#>  [1] /Library/Frameworks/R.framework/Versions/4.1/Resources/library
#> 
#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```
