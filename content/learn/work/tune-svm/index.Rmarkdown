---
title: "그리드서치로 모델 튜닝하기"
tags: [rsample, parsnip, tune, yardstick]
categories: [model tuning]
type: learn-subsection
weight: 1
description: | 
  그리드에서 훈련하여 하이퍼파라미터 선택하기
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
```
  
```{r load, include=FALSE}
library(tidymodels)
library(mlbench)
library(kernlab)
library(doMC)
registerDoMC(cores = parallel::detectCores())

pkgs <- c("tidymodels", "mlbench", "kernlab")

theme_set(theme_bw() + theme(legend.position = "top"))
```

## 들어가기

`r req_pkgs(pkgs)`

이 장에서는 그리드서치를 사용하여 모델을 튜닝하는 방법을 시연합니다.
모델을 훈련할 때 하나의 데이터셋에서 직접 학습할 수 없는 **하이퍼파라미터** 가 많이 있습니다.
가능한 하이퍼파라미터 값들로 이루어진 그리드에서 모델을 여러번 훈편하고 가장 좋은 것을 발견할 수 있습니다.

## 예제 데이터

모델 튜닝을 시연하기 위해, mlbench 패키지의 Ionosphere 데이터를 사용할 수 있습니다:

```{r load-data}
library(tidymodels)
library(mlbench)
data(Ionosphere)
```

`?Ionosphere` 를 하면:

> 이 레이더 데이터는 Labrador, Goose Bay 의 시스템에서 수집되었다. 이 시스템은 6.4 킬로와트 수준의 transmitted power 가 있는 16개의 고주파 안테나의 phased array 로 이루어져 있다. 자세한 내용은 논문을 살펴보라. 목표는 ionosphere 의 자유 전자였다. "좋은" 레이더는 ionosphere 의 어떤 유형의 구조 증거를 보여주는 것을 반환한다. "나쁜" 레이더는 그렇지 않은 것을 반환한다; 신호가 ionosphere 를 투과한다.

> 펄스 시간과 펄스 숫자를 인수로 가지는 autocorrelation 함수를 사용하여 수신된 신호가 처리되었다. Goose Bay 시스템에는 17 펄스 숫자가 있었다. 이 데이터베이스의 인스턴스들은 펄스 숫자당 2 개의 attribute 가 기술하는데, 복잡한 전자기 신호에서 나오는 함수가 반환하는 complex value 에 해당한다. 

43 개의 설명변수와 팩터형 아웃컴이 있습니다. 
설명변수 두 개는 팩터형이고  (`V1`, `V2`), 나머지는 -1 에서 1 의 범위로 스케일된 수치형 변수입니다.
두 개의 팩터형 설명변수는 희소 분포를 가집니다:

```{r factor-pred}
table(Ionosphere$V1)
table(Ionosphere$V2)
```

`V2` 는 0-분산 설명변수이므로 이를 모델에 넣는 것은 의미가 없습니다.
`V1` 도 0-분산은 아니지만, resampling 과정에서 같은 값이 모두 뽑힌다면 그럴 _가능성이 있습니다_.
이것이 이슈일까요?
표준 R 공식 인프라는 관측값이 하나만 있다면 에러가 납니다:

```{r glm-fail, error=TRUE}
glm(Class ~ ., data = Ionosphere, family = binomial)

# Surprisingly, this doesn't help: 

glm(Class ~ . - V2, data = Ionosphere, family = binomial)
```

문제가 있는 두 개의 변수들을 제거해 봅시다:

```{r ion-rm}
Ionosphere <- Ionosphere %>% select(-V1, -V2)
```

## 서치 인풋

radial basis 함수 서포트벡터머신을 이 데이터에 적합하고 SVM 코스트 파라미터와 커널 함수에서 $\sigma$ 파라미터를 튠할 것입니다:

```{r svm-mod}
svm_mod <-
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab")
```

이 장에서, 다음을 사용하여 튜닝을 두 가지 방법으로 보여줄 것입니다:

- 표준 R 공식 
- 레시피

간단한 레시피를 생성해 봅시다:

```{r rec}
iono_rec <-
  recipe(Class ~ ., data = Ionosphere)  %>%
  # remove any zero variance predictors
  step_zv(all_predictors()) %>% 
  # remove any linear combinations
  step_lincomb(all_numeric())
```

마지막으로 튜닝에 필요한 것은 rsample 객체로 정의할 수 있는 resampling 전략입니다. 
기초 부트스트래핑을 이용하는 것을 해봅시다:

```{r rs}
set.seed(4943)
iono_rs <- bootstraps(Ionosphere, times = 30)
```


## 선택적 인풋

모델 튜닝에서 _선택적_ 단계는 out-of-sample 예측을 사용하여 계산해야하는 메트릭을 명시하는 것입니다.
분류에서, 기본값은 log-likelihood 통계량과 종합 정확도를 계산하는 것입니다.
기본값 대신, AUROC 를 사용할 것입니다.
yardstick 패키지에 있는 함수를 사용하여 메트릭들을 생성할 수 있습니다:

```{r roc}
roc_vals <- metric_set(roc_auc)
```

그리드나 파라미터가 없다면, space-filling 디자인(라틴 방격법을 통한)을 이용하여 10 개의 하이퍼파라미터 세트가 생성됩니다.
그리드는 파라미터들이 열에 있고, 파라미터 조합이 행에 있는 데이터프레임으로 제공할 수 있습니다.
여기에, 기본값이 사용될 것입니다.

또한, 서치의 다른 면을 명시하는 컨트롤 객체를 전달할 수도 있습니다.
여기에, verbose 옵션은 껐고, out-of-sample 예측을 저장하는 옵션은 켰습니다.

```{r ctrl}
ctrl <- control_grid(verbose = FALSE, save_pred = TRUE)
```

## 공식으로 실행하기

첫번째로, 공식 인터페이스를 사용할 수 있습니다:

```{r grid, message=FALSE}
set.seed(35)
formula_res <-
  svm_mod %>% 
  tune_grid(
    Class ~ .,
    resamples = iono_rs,
    metrics = roc_vals,
    control = ctrl
  )
formula_res
```

`.metrics` 열에는 각 튜닝 파라미터 조합의 성능 지표 티블이 있습니다:

```{r raw-metrics}
formula_res %>% 
  select(.metrics) %>% 
  slice(1) %>% 
  pull(1)
```

최종 리샘플링 추정값을 얻기 위해, `collect_metrics()` 함수를 그리드 객체에 사용할 수 있습니다:

```{r metric-estimates}
estimates <- collect_metrics(formula_res)
estimates
```

가장 좋은 조합은:

```{r sorted-metrics}
show_best(formula_res, metric = "roc_auc")
```

##  레시피로 실행하기

다음으로, 문법은 같지만, 전처리 인수로 *레시피*를 전달할 수 있습니다:

```{r recipe}
set.seed(325)
recipe_res <-
  svm_mod %>% 
  tune_grid(
    iono_rec,
    resamples = iono_rs,
    metrics = roc_vals,
    control = ctrl
  )
recipe_res
```

여기서 가장 좋은 설정은:

```{r best-rec}
show_best(recipe_res, metric = "roc_auc")
```

## Out-of-sample 예측

`save_pred = TRUE` 를 해서 튜닝하는 동안 각 리샘플에 대해 out-of-sample 예측값들을 저장하면, `collect_predictions()` 을 사용하여 이러한 예측값들을 튜닝 파라미터와 리샘플 식별자와 함께 얻을 수 있습니다:

```{r rec-preds}
collect_predictions(recipe_res)
```

`augment()` 를 사용하여 예측값들이 붙어 있는 모든 리샘플의 hold-out 세트를 얻을 수 있는데, 모델 결과의 유연한 시각화를 할 수 있습니다:

```{r augment-preds}
augment(recipe_res) %>%
  ggplot(aes(V3, .pred_good, color = Class)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~Class)
```

## 세션정보

```{r si, echo = FALSE}
small_session(pkgs)
```
