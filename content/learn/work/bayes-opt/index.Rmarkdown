---
title: "분류 모델의 반복적 베이지언 최적화"
tags: [tune, dials, parsnip, recipes, workflows]
categories: [model tuning]
type: learn-subsection
weight: 3
description: | 
  반복적 탐색의 베이지언 최적화를 사용한 최적 모델 하이퍼파라미터 식별하기.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
```
  
```{r load, include=FALSE}
library(tidymodels)
library(tune)
library(kernlab)
library(rlang)
library(doMC)
library(themis)
registerDoMC(cores = parallel::detectCores())

pkgs <- c("modeldata", "kernlab", "tidymodels", "themis")

theme_set(theme_bw() + theme(legend.position = "top"))
```

## 들어가기

`r req_pkgs(pkgs)`

모델 튜닝의 많은 예제들은 [grid search](/learn/work/tune-svm/)에 집중합니다. 이 방법에 관해, 모든 후보 튜닝 파라미터 조합들은 평가 이전에 정의됩니다. 대안적인 방법으로 _반복탐색(iterative search)_ 을 사용하여 기존 튜닝파라미터 결과를 분석하고 어떤 튜닝 파라미터를 다음에 시도해야하는지 _예측_ 하는 방법도 있습니다. 

다양한 반복탐색 방법이 있는데 이 장의 주제는 _베이지언최적화_ 입니다. 이 방법에 관한 정보는 다음의 자료들이 도움을 줍니다:

* [_Practical bayesian optimization of machine learning algorithms_](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C7&q=Practical+Bayesian+Optimization+of+Machine+Learning+Algorithms&btnG=) (2012). J Snoek, H Larochelle, and RP Adams. Advances in neural information.  

* [_A Tutorial on Bayesian Optimization for Machine Learning_](https://www.cs.toronto.edu/~rgrosse/courses/csc411_f18/tutorials/tut8_adams_slides.pdf) (2018). R Adams.

 * [_Gaussian Processes for Machine Learning_](http://www.gaussianprocess.org/gpml/) (2006). C E Rasmussen and C Williams.

* [Other articles!](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C7&q="Bayesian+Optimization"&btnG=)


## 세포 세그멘팅 - 계속

튜닝 모델에 관한 이 접근법을 시연하기 위해, 리샘플링에 관한 [시작하기](/start/resampling/) 장의 세포 세그멘테이션 데이터를 다시 살펴봅시다: 

```{r import-data}
library(tidymodels)
library(modeldata)

# Load data
data(cells)

set.seed(2369)
tr_te_split <- initial_split(cells %>% select(-case), prop = 3/4)
cell_train <- training(tr_te_split)
cell_test  <- testing(tr_te_split)

set.seed(1697)
folds <- vfold_cv(cell_train, v = 10)
```

## 튜닝 스킴

설명변수들이 상당히 상관되어있기 때문에, 레시피를 사용하여 원 설명변수를 주성분 점수로 변환할 수 있습니다. 이 데이터에는 클래스 불균형이 약간 있습니다; 약 `r floor(mean(cells$class == "PS") * 100)`% 의 데이터가 잘못 세그멘트되었습니다. 이를 개선시키기 위해, 데이터는 전처리의 마지막에 다운샘플해서 잘못/잘 세그멘트된 세포가 같은 빈도로 일어나도록 할 것입니다. 레시피를 사용하여 이 모든 전처리를 할 수 있지만, 주성분 개수는 _튜닝_되어서 충분한 (하지만 너무 많지 않은) 데이터 representation 을 가지도록 할 필요가 있을 것입니다.

```{r recipe}
library(themis)

cell_pre_proc <-
  recipe(class ~ ., data = cell_train) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = tune()) %>%
  step_downsample(class)
```

이 분석에서, 서포트벡터머신을 사용하여 데이터 모델링을 할 것입니다. radial basis function (RBF) 커널을 사용하고 메인 파라미터 ($\sigma$) 를 튜닝해 봅시다. 또한 메인 SVM 파라미터인, 비용값(cost value)도 최적화 될 필요가 있습니다. 

```{r model}
svm_mod <-
  svm_rbf(mode = "classification", cost = tune(), rbf_sigma = tune()) %>%
  set_engine("kernlab")
```


이 레시피와 모델, 두 객체는 [workflows](https://tidymodels.github.io/workflows/) 패키지의 `workflow()` 함수를 이용하여 하나의 객체로 결합될 것입니다; 이 객체는 최적화 과정에서 사용될 것입니다. 

```{r workflow}
svm_wflow <-
  workflow() %>%
  add_model(svm_mod) %>%
  add_recipe(cell_pre_proc)
```

이 객체로 부터, 어떤 파라미터가 스레이트에 올라와 있어서 튜닝될 것인지에 관한 정보를 추출할 수 있습니다. 파라미터셋은 다음으로 추출됩니다:

```{r pset}
svm_set <- parameters(svm_wflow)
svm_set
```

PCA 성분의 개수의 기본값 범위는 이 데이터셋에 좁은 편입니다. 파라미터셋의 구성요소는 `update()` 함수를 사용하여 수정할 수 있습니다. `num_comp` 파라미터를 업데이트해서 1 에서 20 개 성분으로 탐색을 제약해 봅시다. 추가적으로, 이 파라미터의 lower bound 를 0으로 설정하여 원 설명변수 셋도 evaluate 될 수 있게 합니다. (즉, PCA 단계를 전혀 하지 않음):

```{r update}
svm_set <- 
  svm_set %>% 
  update(num_comp = num_comp(c(0L, 20L)))
```

## 순차 튜닝

베이지언 최적화는 새로운 후보 파라미터를 예측하는 모델을 사용하는 순차 방법론입니다. 잠재 파라미터 값을 스코어링할 때, 성능 평균과 분산이 예측됩니다. 이러한 두 통계량을 어떻게 사용할지를 정의하는데 사용되는 전략은 _acquisition function_ 이 정의합니다.

예를들어, 새로운 후보를 스코어링하는 전략 중 하나는 신뢰 범위(bound)를 사용하는 것입니다. 정확도가 최적화되고 있다고 합시다. 우리가 최적화하고 싶은 지표에 관해, lower confidence bound 가 사용됩니다. 표준오차 ($\kappa$ 로 표시) 의 multiplier 는 **exploration** 과 **exploitation** 사이의 트레이드오프를 만드는 데 사용될 수 있는 값입니다.

 * **Exploration** 은 탐색이 테스트되지 않은 공간의 후보들을 고려할 것이라는 것을 의미합니다.

 * **Exploitation** 은 과거 가장 좋은 결과를 얻은 영역에 집중합니다.

베이지언 모델이 예측한 분산은 대부분 공간 분산입니다; 이미 평가된 값과 가깝지 않은 후보에 대해서는 분산이 클 것입니다. 표준오차 multiplier 가 높다면, 탐색 프로세스는 가까운 후보 값들 없는 영역은 피할 가능성이 큽니다.

다른 acquisition function 인, _expected improvement_ 를 사용할 것인데, 이는 현재 가장 좋은 결과에 상대적으로 어떤 후보가 도움을 줄 가능성이 큰지를 결정합니다. 이 함수가 기본값입니다. 이 함수들에 관한 정보는 [acquisition functions 패키지 vignette](https://tidymodels.github.io/tune/articles/acquisition_functions.html) 에 있습니다. 

```{r search, cache = TRUE}
set.seed(12)
search_res <-
  svm_wflow %>% 
  tune_bayes(
    resamples = folds,
    # To use non-default parameter ranges
    param_info = svm_set,
    # Generate five at semi-random to start
    initial = 5,
    iter = 50,
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 30, verbose = TRUE)
  )
```

출력되는 티블은 반복수를 위한 열이 추가된 rsample 객체가 열로 있는 스택된 집합입니다:

```{r show-iters}
search_res
```

그리드 탐색에서와 같이, 리샘플 결과들을 요약할 수 있습니다:

```{r summarize-iters}
estimates <- 
  collect_metrics(search_res) %>% 
  arrange(.iter)

estimates
```

초기 후보값셋의 가장좋은 성능은 `AUC = `r max(estimates$mean[estimates$.iter == 0])` ` 였습니다. 가장 좋은 결과는 반복 `r estimates$.iter[which.max(estimates$mean)]` 에서 얻어졌고, 이 때 AUC 값은 `r max(estimates$mean)` 이었습니다. 가장 결과가 좋은 다섯 개는:

```{r best}
show_best(search_res, metric = "roc_auc")
```

탐색 반복 플롯은 다음으로 생성할 수 있습니다:

```{r bo-plot}
autoplot(search_res, type = "performance")
```

대략 비슷한 결과를 낳는 파라미터 조합이 많이 있습니다.

파라미터들이 반복하면서 어떻게 변화했습니까?


```{r bo-param-plot, fig.width=9}
autoplot(search_res, type = "parameters") + 
  labs(x = "Iterations", y = NULL)
```




## Session information

```{r si, echo = FALSE}
small_session(pkgs)
```
 
