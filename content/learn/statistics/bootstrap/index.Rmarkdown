---
title: "부트스트랩 리샘플링과 타이디한 회귀 모델"
tags: [rsample, broom]
categories: [statistical analysis, resampling]
type: learn-subsection
weight: 3
description: | 
  부트스트랩 리샘플링을 적용하여 모델 파라미터에서 불확실성을 추정하기.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
```

```{r load, include = FALSE}
library(tidymodels)
pkgs <- c("tidymodels")

theme_set(theme_bw() + theme(legend.position = "top"))
```


## 들어가기

이 장은 tidymodels 패키지만 필요로 합니다.

적합된 모델들을 타이디한 방법으로 결합하면 부트스트래핑이나 퍼뮤테이션 테스트를 하기 편리합니다. 이러한 방법들은 예를 들면 [Andrew MacDonald here](https://rstudio-pubs-static.s3.amazonaws.com/19698_a4c472606e3c43e4b94720506e49bb7b.html)에 의해 살펴본 적이 있고, [해들리는 dplyr 에 잠재적인 확장으로써 부트스트래핑에 효율적인 서포트를 탐색한 적이 있습니다](https://github.com/hadley/dplyr/issues/269). tidymodels 패키지 [broom](https://broom.tidyverse.org/) 은 이러한 분석을 수행함에 있어 [dplyr](https://dplyr.tidyverse.org/) 에 자연스럽게 녹아듭니다.

부트스트래핑은 데이터셋을 대치하면서 랜덤하게 샘플링한 뒤 각 부트스태랩된 데이터(bootstraped replicate)에 개별적으로 분석을 수행하는 것으로 이루어져 있습니다. 결과 추정치에서의 분산은 그 후 우리 추정값에서의 분산의 좋은 근사값이 됩니다.

`mtcars` 데이터셋에서 무게/마일리지 관계에 비선형 모델을 적합하고 싶다고 해봅시다.

```{r}
library(tidymodels)

ggplot(mtcars, aes(mpg, wt)) + 
    geom_point()
```

(`nls()` 함수를 통해) nonlinear least squares 방법을 사용하여 모델을 적합할 수 있습니다.

```{r}
nlsfit <- nls(mpg ~ k / wt + b, mtcars, start = list(k = 1, b = 0))
summary(nlsfit)

ggplot(mtcars, aes(wt, mpg)) +
    geom_point() +
    geom_line(aes(y = predict(nlsfit)))
```
이렇게 하면 파라미터의 p-value 와 신뢰구간을 얻을 수 있지만, 이들은 실제 데이터에서는 만족하지 않는 모델 가정에 기반한 것입니다. 부트스트래핑은 데이터 성질에 더 로버스트한 신뢰구간과 예측값을 제공하는 널리사용되는 방법입니다.

## 부트스트래핑 모델

rsample 패키지의 `bootstraps()` 함수를 사용하여 부트스트랩 데이터를 샘플할 수 있습니다
우선, 데이터의 각 데이터가 복원 랜덤 샘플링된, 2000 부트스트랩 데이터들을 만듭니다. 결과 객체는 `rset` 인데, `rsplit` 객체들을 하나의 열로 가지고 있는 데이터프레임이 됩니다.

`rsplit` 객체에는 두 개의 메인 구성요소가 있습니다: 분석 데이터셋과 평가 데이터셋이며 각각 `analysis(rsplit)` 과 `assessment(rsplit)` 으로 접근할 수 있습니다. 부트스트랩 샘플에 대해 분석 데이터셋은 부트스트램 샘플 자체이고, 평가 데이터셋은 out-of-bag 샘플들로 구성됩니다.

```{r}
set.seed(27)
boots <- bootstraps(mtcars, times = 2000, apparent = TRUE)
boots
```

각 부트스트랩 샘플에 `nls()` 모델을 적합하기 위해 도우미 함수를 생성해보고 `purr::map()` 을 이용하여 이 함수를 모든 부트스트랩 샘플들에 한번에 적용해 봅시다. 유사하게, 중첩을 풀어서 타이디한 계수 정보를 가진 열 하나를 생성합니다.

```{r}
fit_nls_on_bootstrap <- function(split) {
    nls(mpg ~ k / wt + b, analysis(split), start = list(k = 1, b = 0))
}

boot_models <-
  boots %>% 
  mutate(model = map(splits, fit_nls_on_bootstrap),
         coef_info = map(model, tidy))

boot_coefs <- 
  boot_models %>% 
  unnest(coef_info)
```

The unnested coefficient information contains a summary of each replication combined in a single data frame:

```{r}
boot_coefs
```

## 신뢰구간

We can then calculate confidence intervals (using what is called the [percentile method](https://www.uvm.edu/~dhowell/StatPages/Randomization%20Tests/ResamplingWithR/BootstMeans/bootstrapping_means.html)):

```{r percentiles}
percentile_intervals <- int_pctl(boot_models, coef_info)
percentile_intervals
```

Or we can use histograms to get a more detailed idea of the uncertainty in each estimate:

```{r}
ggplot(boot_coefs, aes(estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(aes(xintercept = .lower), data = percentile_intervals, col = "blue") +
  geom_vline(aes(xintercept = .upper), data = percentile_intervals, col = "blue")
```

The rsample package also has functions for [other types of confidence intervals](https://tidymodels.github.io/rsample/reference/int_pctl.html). 

## Possible model fits

We can use `augment()` to visualize the uncertainty in the fitted curve. Since there are so many bootstrap samples, we'll only show a sample of the model fits in our visualization:

```{r}
boot_aug <- 
  boot_models %>% 
  sample_n(200) %>% 
  mutate(augmented = map(model, augment)) %>% 
  unnest(augmented)

boot_aug
```

```{r}
ggplot(boot_aug, aes(wt, mpg)) +
  geom_line(aes(y = .fitted, group = id), alpha = .2, col = "blue") +
  geom_point()
```

With only a few small changes, we could easily perform bootstrapping with other kinds of predictive or hypothesis testing models, since the `tidy()` and `augment()` functions works for many statistical outputs. As another example, we could use `smooth.spline()`, which fits a cubic smoothing spline to data:

```{r}
fit_spline_on_bootstrap <- function(split) {
    data <- analysis(split)
    smooth.spline(data$wt, data$mpg, df = 4)
}

boot_splines <- 
  boots %>% 
  sample_n(200) %>% 
  mutate(spline = map(splits, fit_spline_on_bootstrap),
         aug_train = map(spline, augment))

splines_aug <- 
  boot_splines %>% 
  unnest(aug_train)

ggplot(splines_aug, aes(x, y)) +
  geom_line(aes(y = .fitted, group = id), alpha = 0.2, col = "blue") +
  geom_point()
```



## Session information

```{r si, echo = FALSE}
small_session(pkgs)
```
 
 
