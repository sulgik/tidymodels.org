---
title: "모델 계수 작업하기"
tags: [parsnip,tune,broom,workflows]
categories: [model fitting]
type: learn-subsection
weight: 5
description: | 
  계수가 있는 모델을 생성하고, 적합된 모델에서 계수를 추출하고, 시각화한다.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
pkgs <- c("tidymodels", "glmnet")
library(Matrix)
library(glmnet)
```

## 들어가기 

통계 모델은 다양한 구조를 갖습니다.
어떤 모델은 각 항마다 계수(coefficient, weight)를 가지고 있습니다.
이러한 모델의 쉬운 예는 선형 혹은 로지스틱회귀이지만, 더 복잡한 모델 (예: 뉴럴네트워크, MARS)에도 모델 계수가 있습니다.
웨이트나 계수를 가진 모델으로 작업할 때 추정한 계수를 확인하고 싶은 경우가 많습니다.

이 장에서 tidymodels 를 사용하여 모델 적합 객체로 부터 계수 추정값을 추출하는 법에 대해 알아봅니다.
`r req_pkgs(pkgs)`

## 선형 회귀

선형 회귀모델부터 시작해 봅시다:

$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1x_1 + \ldots + \hat{\beta}_px_p$$ 

$\beta$는 계수이고 $x_j$ 은 모델 설명변수 이거나 피쳐입니다.

[시카고 기차 데이터](https://bookdown.org/max/FES/chicago-intro.html) 에서 세 역의 14일 이전 승차데이터를 이용하여 Clark 역과 Lake 역의 얼마나 승차할지를 예측해 봅시다.

modeldata 패키지에 데이터가 있습니다:

```{r setup-tm, message = FALSE, warning=FALSE}
library(tidymodels)
tidymodels_prefer()
theme_set(theme_bw())

data(Chicago)

Chicago <- Chicago %>% select(ridership, Clark_Lake, Austin, Harlem)
```

### 단일 모델

단일한 parsnip 모델 객체를 적합하는 것부터 시작해 봅시다.
`linear_reg()` 를 하여 모델 specification 을 생성할 것입니다. 

{{% note %}} The default engine is `"lm"` so no call to `set_engine()` is required. {{%/ note %}}

공식과 데이터셋이 주어질 때, `fit()` 함수는 모델 계수를 추정합니다.

```{r lm-single}
lm_spec <- linear_reg()
lm_fit <- fit(lm_spec, ridership ~ ., data = Chicago)
lm_fit
```

적합된 파라미터를 추출하려면 `tidy()` 를 사용하는 것이 가장 좋습니다.
broom 패키지에 있는 이 함수는 계수와, 연관된 통계량을 데이터프레임에 표준화된 열이름과 함께 반환합니다:

```{r lm-tidy}
tidy(lm_fit)
```

이후 섹션에서 이 함수를 사용합니다.


### 리샘플되거나 튜닝된 모델

tidymodels 프레임워크에서는 리샘플링 방법들로 모델 성능을 평가하는 것을 강조합니다. 
시계열 리샘플링 방법이 이 데이터에 적절하지만, 데이터를 리샘플하는 [bootstrap](https://www.tmwr.org/resampling.html#bootstrap) 방법을 이용할 수도 있습니다.
bootstrap 방법은 통계적 추정값의 불확실성을 평가할 때 표준적인 리샘플링 방법입니다.

플롯과 아웃풋을 단순화하기 위해 다섯 bootstrap 리샘플을 사용할 것입니다. (원래는 믿을만한 추정값을 위해서는 더 많은 개수의 리샘플을 사용합니다).

```{r bootstraps}
set.seed(123)
bt <- bootstraps(Chicago, times = 5)
```

리샘플링이 만든 데이터셋의 다른 시뮬레이션 버전에 동일한 모델을 적합시킵니다. 
tidymodels 의 [`fit_resamples()`](https://www.tmwr.org/resampling.html#resampling-performance) 함수를 사용하는 것을 추천합니다.

{{% warning %}} The `fit_resamples()` function does not automatically save the model objects for each resample since these can be quite large and its main purpose is estimating performance. However, we can pass a function to `fit_resamples()` that _can_ save the model object or any other aspect of the fit. {{%/ warning %}}

이 함수는 적합된 [워크플로우 객체](https://www.tmwr.org/workflows.html) 를 표현하는 인수를 입력으로 합니다. (`fit_resamples()` 에 워크플로우를 알려주지 않을지라도 그렇습니다.)

이제 모델적합을 추출할 수 있습니다. 
모델 객체의 두 "레벨"을 볼 수 있습니다:

* parsnip 모델객체: 내부 모델객체를 래핑함. `extract_fit_parsnip()` 함수로 추출함. 

* `extract_fit_engine()` 를 통한 내부 모델객체 (다른말로는 엔진적합). 

이전 섹션에서 했듯이 후자 옵션을 사용하여 이 모델객체를 타이디하게 할 것입니다. 
재사용할 수 있도록 컨트롤 함수에 추가합시다.

```{r lm-ctrl}
get_lm_coefs <- function(x) {
  x %>% 
    # get the lm model object
    extract_fit_engine() %>% 
    # transform its format
    tidy()
}
tidy_ctrl <- control_grid(extract = get_lm_coefs)
```

이후 이 인수를 `fit_resamples()` 에 전달합니다:

```{r lm-resampled}
lm_res <- 
  lm_spec %>% 
  fit_resamples(ridership ~ ., resamples = bt, control = tidy_ctrl)
lm_res
```

리샘플링 결과에 `.extracts` 열이 생겼습니다.
이 객체에는 각 리샘플에 대한 `get_lm_coefs()` 아웃풋이 있습니다.
이 `.extracts` 열 구조는 조금 복잡합니다.
첫번째 요소 (첫번째 리샘플에 해당) 를 보는 것으로 시작합시다:

```{r lm-extract-ex}
lm_res$.extracts[[1]]
```

이 요소에는 `tidy()` 함수 호출 결과를 가진 `.extracts` 이름의 _또다른_ 열이 있습니다:

```{r lm-extract-again}
lm_res$.extracts[[1]]$.extracts[[1]]
```

이러한 중첩된 열들은 purrr `unnest()` 함수를 통해 flat 하게 만들수 있습니다: 

```{r lm-extract-almost}
lm_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) 
```

중첩된 티블 열이 여전히 남아있기 때문에, 데이터를 유용한 포맷으로 만드는 같은 명령어를 다시 수행합니다:

```{r lm-extract-final}
lm_coefs <- 
  lm_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  unnest(.extracts)

lm_coefs %>% select(id, term, estimate, p.value)
```

더 나아졌습니다!
이제, 각 리샘플의 모델 계수를 플롯해봅시다.

```{r lm-plot}
lm_coefs %>%
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = term, y = estimate, group = id, col = id)) +  
  geom_hline(yintercept = 0, lty = 3) + 
  geom_line(alpha = 0.3, lwd = 1.2) + 
  labs(y = "Coefficient", x = NULL) +
  theme(legend.position = "top")
```

Austin 역 데이터의 계수에 있어서 uncertainty 가 크고, 다른 두 역에 대해서는 작은 것 같이 보입니다.
결과를 unnest 하는 코드를 보면, double-nesting 구조가 과하거나 귀찮을 것입니다.
그러나, 추출 기능은 유연성이 있고, 더 간단한 구조로는 많은 use case 를 할 수 없었을 것입니다.


## 복잡한 모델: glmnet

glmnet 모델은 위에서 본 것과 같은 선형 회귀모형을 적합할 수 있습니다.
이 모델은 regulization (a.k.a penalization) 을 사용하여  모델 파라키터를 추정합니다.
이렇게 하면 계수를 0 으로 축소시키는데, 설명변수 사이에 상관성이 크거나, 변수 선택이 필요할 때 중요합니다. 
우리 Chiacago 열차데이터셋에 두 경우 다 해당합니다. 

이 모델이 사용하는 두 가지 유형의 penalization 이 있습니다:

* Lasso (a.k.a. $L_1$) 패널티는 절대값 0 이 될 정도로 모델 항을 축소시킬 수 있습니다 (즉, 해당 효과가 모델에서 완전히 제거됨). 

* Weight decay (a.k.a ridge 회귀 혹은 $L_2$) 는 상관성이 강한 설명변수들에 대해 가장 효과적인 유형의 패널티를 사용합니다. 

glmnet 모델은 두 가지의 튜닝파라미터가 있는데, penalization 전체 양과 두 패널티 유형의 mixture 입니다. 예를 들어, 이 specification 은:

```{r glmnet-spec}
glmnet_spec <- 
  linear_reg(penalty = 0.1, mixture = 0.95) %>% 
  set_engine("glmnet")
```

95% lasso 와 5% weight decay 인 패널티를 가집니다. 이 두 패널티의 전체 양은 0.1 (상당히 높은 값) 입니다. 

{{% note %}} Models with regularization require that predictors are all on the same scale. The ridership at our three stations are very different, but glmnet [automatically centers and scales the data](https://parsnip.tidymodels.org/reference/details_linear_reg_glmnet.html). You can use recipes to [center and scale your data yourself](https://recipes.tidymodels.org/reference/step_normalize.html). {{%/ note %}}

모델 specification 과 모델 `workflow()` 의 공식을 결합한 뒤 모델을 데이터에 적합해 봅시다:

```{r glmnet-wflow}
glmnet_wflow <- 
  workflow() %>% 
  add_model(glmnet_spec) %>% 
  add_formula(ridership ~ .)

glmnet_fit <- fit(glmnet_wflow, Chicago)
glmnet_fit
```

이 아웃풋에서, `lambda` 항은 패널티를 나타냅니다.

`penalty = 0.1` specification 에도 불구하고 아웃풋에서 패널티의 여러 값이 출력되었습니다. 패널티 값 "path" 에 적합하는 것입니다. 0.1 값에 관심이 있더라도, 같은 모델 객체의 여러 패널티 값에 대한 모델 계수를 얻을 수 있습니다.

계수를 구하는 두가지 다른 방법을 살펴봅시다. 두 방법 다 `tidy()` 방법을 사용합니다. 한 방법은 glmnet 객체를 타이디하게 하고 다른 방법은, tidymodels 객체를 타이디하게 할 것입니다.

### glmnet 패널티 값을 사용

이 glmnet fit 에는 데이터셋에 의존하는 여러 패널티 값이 있습니다;  
데이터(혹은 mixture 양)를 바꾸면 다른 패널티값이 산출됩니다. 
이 데이터셋에는, `r length(extract_fit_engine(glmnet_fit)$lambda)` 개의 패널티가 있습니다. 
이 데이터셋에서 산출된 패널티를 구하기 위해, 엔진 fit 을 추출하고, 타이디하게 할 수 있습니다:

```{r glmnet-tidy}
glmnet_fit %>% 
  extract_fit_engine() %>% 
  tidy() %>% 
  rename(penalty = lambda) %>%   # <- for consistent naming
  filter(term != "(Intercept)")
```

출력된 것을 보면, 잘 동작한 것 같지만, 우리 패널티 값 (0.1) 이 모델에서 산출한 목록에 없습니다!
내부 패키지에는 interpolation 을 이용하여, 이 구체적 값에 해당하는 계수를 산출하는 함수들이 있지만, glmnet 객체에 대한 `tidy()` 메소드는 이 함수들을 사용하지 않습니다. 

### 특정 패널티 값 사용하기

`tidy()` 메소드를 워크플로나 parsnip 객체에 실행한다면, 우리가 특정한 패널티 값에 해당하는 계수를 반환하는 다른 함수가 사용됩니다: 

```{r glmnet-tidy-parsnip}
tidy(glmnet_fit)
```

다른 (single) 패널티에 대해, 추가 인수를 사용할 수 있습니다:

```{r glmnet-tidy-parsnip-alt}
tidy(glmnet_fit, penalty = 5.5620)  # A value from above
```

두 개의 `tidy()` 메소드가 있는 이유는 tidymodels 에서의 주안점은 특정한 패널티 값에 있기 때문입니다. 


### glmnet 모델 튜닝하기

penalty 와 mixture 에 사전 값을 알고 있다면, 선형회귀에서와 같이 `fit_resamples()` 함수를 사용할 수 있습니다. 
다른 방법으로는 tidymodels `tune_*()` 함수로 이러한 파라미터들을 튜닝할 수 있습니다.
이 그리드로 두개의 파라미터에 대해 glmnet 모델을 튜닝해 봅시다:

```{r glmnet-grid}
pen_vals <- 10^seq(-3, 0, length.out = 10)
grid <- crossing(penalty = pen_vals, mixture = c(0.1, 1.0))
```

여기가 glmnet-관련 복잡도가 더 증가하는 부분입니다: 각 resample 과 가가 `mixture` 값이 모델 객체에 포함된 다른 패널티 값들을 산출할 것입니다. _튜닝을 위해 사용 중인 특정 패널티 값에서 계수들을 어떻게 볼 수 있을까요?_

제안하는 방법은 glmnet 의 특수 `path_values` (패쓰 값) 옵션을 사용하는 것입니다. 
[glmnet 과 tidymodels 에 관한 기술문서](https://parsnip.tidymodels.org/reference/glmnet-details.html#arguments) 에 상세사항이 있지만, 요약하면, 이 파라미터는 각 glmnet 적합이 사용한 패널티 값들 집합을 (데이터나 mixture 값에 상관 없이) 할당할 것입니다. 

이들을 엔진 인수로 전달한 뒤 이전 워크플로 객체를 업데이트할 수 있습니다:

```{r glmnet-tune}
glmnet_tune_spec <- 
  linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine("glmnet", path_values = pen_vals)

glmnet_wflow <- 
  glmnet_wflow %>% 
  update_model(glmnet_tune_spec)
```

ordinary least squared 를 사용했을 때와 유사한 추출 함수를 사용할 것입니다.
추가 인수를 사용하여 lasso 패널티에 의해 0 으로 축소하는 계수들을 남길 것입니다: 

```{r glmnet-tuning}
get_glmnet_coefs <- function(x) {
  x %>% 
    extract_fit_engine() %>% 
    tidy(return_zeros = TRUE) %>% 
    rename(penalty = lambda)
}
parsnip_ctrl <- control_grid(extract = get_glmnet_coefs)

glmnet_res <- 
  glmnet_wflow %>% 
  tune_grid(
    resamples = bt,
    grid = grid,
    control = parsnip_ctrl
  )
glmnet_res
```

전에서 보았듯이, 메인 `.extracts` 열의 구성요소들에는 `get_glmnet_coefs()` 결과가 있는 임베디된 리스트 열이 있습니다:

```{r glmnet-extract-single}
glmnet_res$.extracts[[1]] %>% head()

glmnet_res$.extracts[[1]]$.extracts[[1]] %>% head()
```

전과 같이, `unnest()` 를 두 번 사용해야합니다. 
패널티 값이 top-level 과 lower-level `.extracts` 모두에 있기 때문에, `select()` 를 사용하여 첫 버전을 제거할 것입니다 (`mixture` 는 보관).

```{r glmnet-extract-1, eval = FALSE}
glmnet_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  select(id, mixture, .extracts) %>%  # <- removes the first penalty column
  unnest(.extracts)
```

잠깐! 각 glmnet 적합에 계수들 모두가 있는 걸 알고 있습니다. 
특정 resample 과 `mixture` 값에 대해 결과가 같다는 것을 의미합니다:  

```{r glmnet-extract-dups}
all.equal(
  # First bootstrap, first `mixture`, first `penalty`
  glmnet_res$.extracts[[1]]$.extracts[[1]],
  # First bootstrap, first `mixture`, second `penalty`
  glmnet_res$.extracts[[1]]$.extracts[[2]]
)
```

이러한 이유로, `id` 와 `mixture` 로 그루핑할 때 slice(1)` 을 추가할 것입니다. 
동일한 결과가 제거됩니다.

```{r glmnet-extract-final}
glmnet_coefs <- 
  glmnet_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  select(id, mixture, .extracts) %>% 
  group_by(id, mixture) %>%          # ┐
  slice(1) %>%                       # │ Remove the redundant results
  ungroup() %>%                      # ┘
  unnest(.extracts)

glmnet_coefs %>% 
  select(id, penalty, mixture, term, estimate) %>% 
  filter(term != "(Intercept)")
```

계수들이 있습니다. 
더 많은 regularization 이 사용될 때 계수들이 어떻게 바뀌는지 살펴봅시다: 

```{r glmnet-plot, fig.height=4, fig.width=8.5}
glmnet_coefs %>% 
  filter(term != "(Intercept)") %>% 
  mutate(mixture = format(mixture)) %>% 
  ggplot(aes(x = penalty, y = estimate, col = mixture, groups = id)) + 
  geom_hline(yintercept = 0, lty = 3) +
  geom_line(alpha = 0.5, lwd = 1.2) + 
  facet_wrap(~ term) + 
  scale_x_log10() +
  scale_color_brewer(palette = "Accent") +
  labs(y = "coefficient") +
  theme(legend.position = "top")
```

다음을 알 수 있습니다: 

* 순수 lasso 모델 (즉, `mixture = 1`)에서, Austin 역 설명변수는 각 resample 에서 선택되지 않았다.두 패널티 mixture 에서, 영향도가 증가한다. 또한, 패널티가 증가하면, 이 계수의 불확실성은 감소한다. 

* Harlem 설명변수는 빠르게 모델에서 제외되거나 음수에서 양수로 변한다. 

## 세션정보

```{r si, echo = FALSE}
small_session(pkgs)
```
