---
title: "모델 계수 작업하기"
tags: [parsnip,tune,broom,workflows]
categories: [model fitting]
type: learn-subsection
weight: 5
description: | 
  계수가 있는 모델을 생성하고, 적합된 모델에서 계수를 추출하고, 시각화한다.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
pkgs <- c("tidymodels", "glmnet")
library(Matrix)
library(glmnet)
```

## 들어가기 

통계 모델은 다양한 구조를 갖습니다.
어떤 모델은 각 항마다 계수(coefficient, weight)를 가지고 있습니다.
이러한 모델의 쉬운 예는 선형 혹은 로지스틱회귀이지만, 더 복잡한 모델 (예: 뉴럴네트워크, MARS)에도 모델 계수가 있습니다.
웨이트나 계수를 가진 모델으로 작업할 때 추정한 계수를 확인하고 싶은 경우가 많습니다.

이 장에서 tidymodels 를 사용하여 모델 적합 객체로 부터 계수 추정값을 추출하는 법에 대해 알아봅니다.
`r req_pkgs(pkgs)`

## 선형 회귀

선형 회귀모델부터 시작해 봅시다:

$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1x_1 + \ldots + \hat{\beta}_px_p$$ 

$\beta$는 계수이고 $x_j$ 은 모델 설명변수 이거나 피쳐입니다.

[시카고 기차 데이터](https://bookdown.org/max/FES/chicago-intro.html) 에서 Clark 와 Lake 역의 승차를 세 역의 14일 이전 승차데이터를 이용하여 예측해 봅시다.

modeldata 패키지에 데이터가 있습니다:

```{r setup-tm, message = FALSE, warning=FALSE}
library(tidymodels)
tidymodels_prefer()
theme_set(theme_bw())

data(Chicago)

Chicago <- Chicago %>% select(ridership, Clark_Lake, Austin, Harlem)
```

### 단일 모델

단일한 parsnip 모델 객체를 적합하는 것부터 시작해 봅시다.
`linear_reg()` 를 하여 모델 specification 을 생성할 것입니다. 

{{% note %}} The default engine is `"lm"` so no call to `set_engine()` is required. {{%/ note %}}

공식과 데이터셋이 주어질 때, `fit()` 함수는 모델 계수를 추정합니다.

```{r lm-single}
lm_spec <- linear_reg()
lm_fit <- fit(lm_spec, ridership ~ ., data = Chicago)
lm_fit
```

`tidy()` 방법을 사용하는 것이 적합된 파라미터를 추출하는 가장 좋은 방법입니다.
broom 패키지에 있는 이 함수는 계수와, 연관된 통계량을 데이터프레임에 표준화된 열이름과 함께 반환합니다:

```{r lm-tidy}
tidy(lm_fit)
```

이후 섹션에서 이 함수를 사용합니다.

### 리샘플되거나 튜닝된 모델

tidymodels 프레임워크에서는 리샘플링 방법들로 모델 성능을 평가하는 것을 강조합니다. 
시게열 리샘플링 방법이 이 데이터에 적절하지만, 데이터를 리샘플하는 [bootstrap](https://www.tmwr.org/resampling.html#bootstrap) 방법을 이용할 수도 있습니다.
bootstrap 방법은 통계적 추정값의 불확실성을 평가할 때 표준적인 리샘플링 방법입니다.

플롯과 아웃풋을 단순화하기 위해 다섯 bootstrap 리샘플을 사용할 것입니다. (원래는 믿을만한 추정값을 위해서는 더 많은 개수의 리샘플을 사용합니다).

```{r bootstraps}
set.seed(123)
bt <- bootstraps(Chicago, times = 5)
```

리샘플링이 만든 데이터셋의 다른 시뮬레이션 버전에 동일한 모델을 적합시킵니다. 
추천하는 방법은 tidymodels 함수 [`fit_resamples()`](https://www.tmwr.org/resampling.html#resampling-performance)를 사용하는 것입니다.

{{% warning %}} The `fit_resamples()` function does not automatically save the model objects for each resample since these can be quite large and its main purpose is estimating performance. However, we can pass a function to `fit_resamples()` that _can_ save the model object or any other aspect of the fit. {{%/ warning %}}

이 함수는 적합된 [워크플로우 객체](https://www.tmwr.org/workflows.html) 를 표현하는 인수를 입력으로 합니다. (`fit_resamples()` 에 워크플로우를 알려주지 않을지라도 그렇습니다.)

이제 모델 적합을 추출할 수 있습니다. 
모델 객체의 두 "레벨"을 볼 수 있습니다:

* parsnip 모델객체: 내부 모델객체를 래핑함. `extract_fit_parsnip()` 함수로 추출함. 

* `extract_fit_engine()` 를 통한 내부 모델객체 (aka 엔진적합). 

후자 옵션을 사용하여 이 모델객체를 이전섹션에서 했듯이 타이디하게 할 것입니다. 
이를 재사용할 수 있도록 컨트롤 함수에 추가합시다.

```{r lm-ctrl}
get_lm_coefs <- function(x) {
  x %>% 
    # get the lm model object
    extract_fit_engine() %>% 
    # transform its format
    tidy()
}
tidy_ctrl <- control_grid(extract = get_lm_coefs)
```

이후 이 인수를 `fit_resamples()` 에 전달합니다:

```{r lm-resampled}
lm_res <- 
  lm_spec %>% 
  fit_resamples(ridership ~ ., resamples = bt, control = tidy_ctrl)
lm_res
```

리샘플링 결과에 `.extracts` 열이 생겼습니다.
이 객체에는 각 리샘플에 대한 `get_lm_coefs()` 아웃풋이 있습니다.
이 `.extracts` 열 구조는 조금 복잡합니다.
첫번째 요소 (첫번째 리샘플에 해당) 를 보는 것으로 시작합시다:

```{r lm-extract-ex}
lm_res$.extracts[[1]]
```

이 요소에는 `tidy()` 함수 호출 결과를 가진 `.extracts` 이름의 _또다른_ 열이 있습니다:

```{r lm-extract-again}
lm_res$.extracts[[1]]$.extracts[[1]]
```

이러한 중첩된 열들은 purrr `unnest()` 함수를 통해 flat 하게 만들수 있습니다: 

```{r lm-extract-almost}
lm_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) 
```

중첩된 티블 열이 여전히 남아있기 때문에, 데이터를 유용한 포맷으로 만드는 같은 명령어를 다시 수행합니다:

```{r lm-extract-final}
lm_coefs <- 
  lm_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  unnest(.extracts)

lm_coefs %>% select(id, term, estimate, p.value)
```

더 나아졌습니다!
이제, 각 리샘플의 모델 계수를 플롯해봅시다.

```{r lm-plot}
lm_coefs %>%
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = term, y = estimate, group = id, col = id)) +  
  geom_hline(yintercept = 0, lty = 3) + 
  geom_line(alpha = 0.3, lwd = 1.2) + 
  labs(y = "Coefficient", x = NULL) +
  theme(legend.position = "top")
```

Austin 역 데이터의 계수에 있어서 uncertainty 가 크고, 다른 두 역에 대해서는 작은 것 같이 보입니다.
결과를 unnest 하는 코드를 보면, double-nesting 구조가 과하거나 귀찮을 것입니다.
그러나, 추출 기능은 유연성이 있고, 더 간단한 구조로는 많은 use case 를 할 수 없었을 것입니다.

## 복잡한 모델: glmnet

glmnet 모델은 위에서 본 것과 같은 선형 회귀모형을 적합할 수 있습니다.
이 모델은 regulization (a.k.a penalization) 을 사용하여  모델 파라키터를 추정합니다.
이렇게 하면 계수를 0 으로 축소시키는데, 설명변수 사이에 상관성이 크거나, 변수 선택이 필요할 때 중요합니다. 
우리 Chiacago 열차데이터셋에 두 경우 다 해당합니다. 

이 모델이 사용하는 두 가지 유형의 penalization 이 있습니다:

* Lasso (a.k.a. $L_1$) 페널티는 절대값 0 이 될 정도로 모델 항을 축소시킬 수 있습니다 (즉, 해당 효과가 모델에서 완전히 제거됨). 

* Weight decay (a.k.a ridge 회귀 혹은 $L_2$) 는 상관성이 강한 설명변수들에 대해 가장 효과적인 유형의 페널티를 사용합니다. 

glmnet 모델은 두 가지의 튜닝파라미터가 있는데, penalization 전체 양과 두 페널티 유형의 mixture 입니다. 예를 들어, 이 specification 은:

```{r glmnet-spec}
glmnet_spec <- 
  linear_reg(penalty = 0.1, mixture = 0.95) %>% 
  set_engine("glmnet")
```

95% lasso 와 5% weight decay 인 페널티를 가집니다. 이 두 페널티의 전체 양은 0.1 (상당히 높은 값) 입니다. 

{{% note %}} Models with regularization require that predictors are all on the same scale. The ridership at our three stations are very different, but glmnet [automatically centers and scales the data](https://parsnip.tidymodels.org/reference/details_linear_reg_glmnet.html). You can use recipes to [center and scale your data yourself](https://recipes.tidymodels.org/reference/step_normalize.html). {{%/ note %}}

모델 specification 과 모델 `workflow()` 의 공식을 결합한 뒤 모델을 데이터에 적합해 봅시다:

```{r glmnet-wflow}
glmnet_wflow <- 
  workflow() %>% 
  add_model(glmnet_spec) %>% 
  add_formula(ridership ~ .)

glmnet_fit <- fit(glmnet_wflow, Chicago)
glmnet_fit
```

이 아웃풋에서, `lambda` 항은 페널티를 나타냅니다.

`penalty = 0.1` specification 에도 불구하고 아웃풋에서 페널티의 여러 값이 출력되었습니다. 페널티 값 "path" 에 적합하는 것입니다. 0.1 값에 관심이 있더라도, 같은 모델 객체의 여러 패널티 값에 대한 모델 계수를 얻을 수 있습니다.

계수를 구하는 두가지 다른 방법을 살펴봅시다. 두 방법 다 `tidy()` 방법을 사용합니다. 한 방법은 glmnet 객체를 타이디하게 하고 다른 방법은, tidymodels 객체를 타이디하게 할 것입니다.

### glmnet 페널티 값을 사용

이 glmnet fit 에는 데이터셋에 의존하는 여러 패널티 값이 있습니다;  
데이터(혹은 mixture 양)를 바꾸면 다른 패널티값이 산출됩니다. 
이 데이터셋에는, `r length(extract_fit_engine(glmnet_fit)$lambda)` 개의 패널티가 있습니다. 
이 데이터셋에서 산출된 패널티를 구하기 위해, 엔진 fit 을 추출하고, 타이디하게 할 수 있습니다:

```{r glmnet-tidy}
glmnet_fit %>% 
  extract_fit_engine() %>% 
  tidy() %>% 
  rename(penalty = lambda) %>%   # <- for consistent naming
  filter(term != "(Intercept)")
```

출력된 것을 보면, 잘 동작한 것 같지만, 우리 패널티 값 (0.1) 이 모델에서 산출한 목록에 없습니다!
내부 패키지에는 interpolation 을 이용하여, 이 구체적 값에 해당하는 계수를 산출하는 함수들이 있지만, glmnet 객체에 대한 `tidy()` 메소드는 이 함수들을 사용하지 않습니다. 

### 특정 패널티 값 사용하기

`tidy()` 메소드를 워크플로나 parsnip 객체에 실행한다면, 우리가 특정한 패널티 값에 해당하는 계수를 반환하는 다른 함수가 사용됩니다: 

```{r glmnet-tidy-parsnip}
tidy(glmnet_fit)
```

다른 (single) 패널티에 대해, 추가 인수를 사용할 수 있습니다:

```{r glmnet-tidy-parsnip-alt}
tidy(glmnet_fit, penalty = 5.5620)  # A value from above
```

두 개의 `tidy()` 메소드가 있는 이유는 tidymodels 에서의 주안점은 특정한 패널티 값에 있기 때문입니다. 


### glmnet 모델 튜닝하기

If we know a priori acceptable values for penalty and mixture, we can use the `fit_resamples()` function as we did before with linear regression. Otherwise, we can tune those parameters with the tidymodels `tune_*()` functions. 

Let's tune our glmnet model over both parameters with this grid: 

```{r glmnet-grid}
pen_vals <- 10^seq(-3, 0, length.out = 10)
grid <- crossing(penalty = pen_vals, mixture = c(0.1, 1.0))
```

Here is where more glmnet-related complexity comes in: we know that each resample and each value of `mixture` will probably produce a different set of penalty values contained in the model object. _How can we look at the coefficients at the specific penalty values that we are using to tune?_

The approach that we suggest is to use the special `path_values` option for glmnet. Details are described in the [technical documentation about glmnet and tidymodels](https://parsnip.tidymodels.org/reference/glmnet-details.html#arguments) but in short, this parameter will assign the collection of penalty values used by each glmnet fit (regardless of the data or value of mixture). 

We can pass these as an engine argument and then update our previous workflow object:

```{r glmnet-tune}
glmnet_tune_spec <- 
  linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine("glmnet", path_values = pen_vals)

glmnet_wflow <- 
  glmnet_wflow %>% 
  update_model(glmnet_tune_spec)
```

Now we will use an extraction function similar to when we used ordinary least squares. We add an additional argument to retain coefficients that are shrunk to zero by the lasso penalty: 

```{r glmnet-tuning}
get_glmnet_coefs <- function(x) {
  x %>% 
    extract_fit_engine() %>% 
    tidy(return_zeros = TRUE) %>% 
    rename(penalty = lambda)
}
parsnip_ctrl <- control_grid(extract = get_glmnet_coefs)

glmnet_res <- 
  glmnet_wflow %>% 
  tune_grid(
    resamples = bt,
    grid = grid,
    control = parsnip_ctrl
  )
glmnet_res
```

As noted before, the elements of the main `.extracts` column have an embedded list column with the results of `get_glmnet_coefs()`:  

```{r glmnet-extract-single}
glmnet_res$.extracts[[1]] %>% head()

glmnet_res$.extracts[[1]]$.extracts[[1]] %>% head()
```

As before, we'll have to use a double `unnest()`. Since the penalty value is in both the top-level and lower-level `.extracts`, we'll use `select()` to get rid of the first version (but keep `mixture`):

```{r glmnet-extract-1, eval = FALSE}
glmnet_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  select(id, mixture, .extracts) %>%  # <- removes the first penalty column
  unnest(.extracts)
```

But wait! We know that each glmnet fit contains all of the coefficients. This means, for a specific resample and value of `mixture`, the results are the same:  

```{r glmnet-extract-dups}
all.equal(
  # First bootstrap, first `mixture`, first `penalty`
  glmnet_res$.extracts[[1]]$.extracts[[1]],
  # First bootstrap, first `mixture`, second `penalty`
  glmnet_res$.extracts[[1]]$.extracts[[2]]
)
```

For this reason, we'll add a `slice(1)` when grouping by `id` and `mixture`. This will get rid of the replicated results. 

```{r glmnet-extract-final}
glmnet_coefs <- 
  glmnet_res %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  select(id, mixture, .extracts) %>% 
  group_by(id, mixture) %>%          # ┐
  slice(1) %>%                       # │ Remove the redundant results
  ungroup() %>%                      # ┘
  unnest(.extracts)

glmnet_coefs %>% 
  select(id, penalty, mixture, term, estimate) %>% 
  filter(term != "(Intercept)")
```

Now we have the coefficients. Let's look at how they behave as more regularization is used: 

```{r glmnet-plot, fig.height=4, fig.width=8.5}
glmnet_coefs %>% 
  filter(term != "(Intercept)") %>% 
  mutate(mixture = format(mixture)) %>% 
  ggplot(aes(x = penalty, y = estimate, col = mixture, groups = id)) + 
  geom_hline(yintercept = 0, lty = 3) +
  geom_line(alpha = 0.5, lwd = 1.2) + 
  facet_wrap(~ term) + 
  scale_x_log10() +
  scale_color_brewer(palette = "Accent") +
  labs(y = "coefficient") +
  theme(legend.position = "top")
```

Notice a couple of things: 

* With a pure lasso model (i.e., `mixture = 1`), the Austin station predictor is selected out in each resample. With a mixture of both penalties, its influence increases. Also, as the penalty increases, the uncertainty in this coefficient decreases. 

* The Harlem predictor is either quickly selected out of the model or goes from negative to positive. 

## 세션정보

```{r si, echo = FALSE}
small_session(pkgs)
```
