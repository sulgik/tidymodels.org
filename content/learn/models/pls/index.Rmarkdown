---
title: "Partial least squares 로 하는 다변량 분석"
tags: [recipes,rsample]
categories: [pre-processing]
type: learn-subsection
weight: 6
description: | 
  하나 이상의 결과가 있는 예측 모델을 만들고 적합하기.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/learn/common.R"))
```

```{r load, include = FALSE}
library(pls)
library(tidymodels)
library(sessioninfo)
pkgs <- c("modeldata", "pls", "tidymodels")

theme_set(theme_bw() + theme(legend.position = "top"))
```


## 들어가기

`r req_pkgs(pkgs)`

"다변량 분석" 은 다중 _아웃컴_ 을 모델링하고, 분석하고 예측하는 것을 의미합니다. 
일반적인 통계 도구들에는 다변량 버전이 있습니다. 
예를 들어, 예측할 두 개의 아웃컴을 의미하는 `y1`, `y2` 열을 가진 데이터셋이 있다고 가정해봅시다. 
`lm()` 함수는 다음과 같이 생겼습니다:

```{r lm, eval = FALSE}
lm(cbind(y1, y2) ~ ., data = dat)
```

이 `cbind` 호출은 꽤 이상한데, 전통적 공식 인프라가 동작방법의 결과입니다.
recipes 패키지는 다루기 훨씬 쉽습니다!
이 장에서 다중 아웃컴을 모델링하는 법을 살펴볼 것입니다.

우리가 사용할 데이터는 아웃컴이 세 개 입니다. `?modeldata::meats` 을 보면:

> "이 데이터는 Tecator Infratec Food 와 근거리 적외선 통신 법칙(NIT)의 주파수 범위 850 - 1050 nm 에서 작동하는 Feed Analyzier 에서 기록되었습니다. 각 샘플에는 습도, 지방, 단백질 성분이 다른 잘게 다져진 고기가 있습니다.

> "각 고기 샘플에 대해 데이터는 100 개의 흡수도 채널 스펙트럼과 습도(물), 지방, 단백질 성분으로 구성되어 있습니다. 흡수도는 spectrometer 가 측정한 `-log10` 의 transmittance 입니다. 퍼센트로 측정한 세 가지 성분은 분석 화학가가 정했습니다. 

화학 테스트를 이용하여 세 성분의 비율을 예측하는 것이 목적입니다. 
설명변수들에 높은 수준의 변수간 상관관계가 있는 경우가 많은데 이 경우가 그렇습니다. 

두 개의 데이터 행렬 (`endpoints` 와 `absorp` 라 부름) 를 가져와서 데이터프레임으로 묶는 것으로 시작해 봅시다:

```{r data}
library(modeldata)
data(meats)
```

세 개의 _아웃컴_ 도 꽤 높은 상관관계를 가집니다.

## 데이터 전처리하기

선형 모형을 이용하여 아웃컴을 예측할 수 있으면, partial least squares (PLS) 이 이상적인 방법이다. 
PLS는 데이터를 관측할 수 없는 _숨겨진_ 변수들의 집합의 함수로 모델링 하는데, 숨겨진 변수는 주성분 분석 (PCA) 와 유사한 방법으로 유도한다.

PCA 와 달리 PLS 는 PLS 성분을 생성할 때 아웃컴 데이터를 이용할 수도 있다. 
PCA 와 같이 PLS 는 이 성분들로 설명되는 설명변수의 분산을 최대화하지만, 동시에 이 성분들과 아웃컴들 사이의 상관관계를 최대화 합니다.
이렇게 하여, PLS 는 설명변ㅅ와 반응변수의 분산을 _쫓아갑니다(chase)_.

분산과 공분산 작업을 하고 있기 때문에, 데이터를 표준화 해야 합니다.
레시피가 모든 변수를 센터링 하고 스케일 할 것입니다.

공식을 사용하는 다변량 아웃컴을 다루는 많은 베이스 R 함수들은 전통적인 공식 방법 작업을 하기 위해 공식의 왼편에 `
Many base R functions that deal with multivariate outcomes using a formula require the use of `cbind()` on the left-hand side of the formula to work with the traditional formula methods. In tidymodels, recipes do not; the outcomes can be symbolically "added" together on the left-hand side:

```{r recipe}
norm_rec <- 
  recipe(water + fat + protein ~ ., data = meats) %>%
  step_normalize(everything()) 
```

Before we can finalize the PLS model, the number of PLS components to retain must be determined. This can be done using performance metrics such as the root mean squared error. However, we can also calculate the proportion of variance explained by the components for the _predictors and each of the outcomes_. This allows an informed choice to be made based on the level of evidence that the situation requires. 

Since the data set isn't large, let's use resampling to measure these proportions. With ten repeats of 10-fold cross-validation, we build the PLS model on 90% of the data and evaluate on the heldout 10%. For each of the 100 models, we extract and save the proportions. 

The folds can be created using the [rsample](https://tidymodels.github.io/rsample/) package and the recipe can be estimated for each resample using the [`prepper()`](https://tidymodels.github.io/rsample/reference/prepper.html) function: 

```{r cv}
set.seed(57343)
folds <- vfold_cv(meats, repeats = 10)

folds <- 
  folds %>%
  mutate(recipes = map(splits, prepper, recipe = norm_rec))
```

## Partial least squares

The complicated parts for moving forward are:

1. Formatting the predictors and outcomes into the format that the pls package requires, and
2. Estimating the proportions. 

For the first part, the standardized outcomes and predictors need to be formatted into two separate matrices. Since we used `retain = TRUE` when prepping the recipes, we can `bake()` with `new_data = NULl` to get the processed data back out. To save the data as a matrix, the option `composition = "matrix"` will avoid saving the data as tibbles and use the required format. 

The pls package expects a simple formula to specify the model, but each side of the formula should _represent a matrix_. In other words, we need a data set with two columns where each column is a matrix. The secret to doing this is to "protect" the two matrices using `I()` when adding them to the data frame.

The calculation for the proportion of variance explained is straightforward for the predictors; the function `pls::explvar()` will compute that. For the outcomes, the process is more complicated. A ready-made function to compute these is not obvious but there is some code inside of the summary function to do the computation (see below). 

The function `get_var_explained()` shown here will do all these computations and return a data frame with columns `components`, `source` (for the predictors, water, etc), and the `proportion` of variance that is explained by the components. 


```{r var-explained}
library(pls)

get_var_explained <- function(recipe, ...) {
  
  # Extract the predictors and outcomes into their own matrices
  y_mat <- bake(recipe, new_data = NULL, composition = "matrix", all_outcomes())
  x_mat <- bake(recipe, new_data = NULL, composition = "matrix", all_predictors())
  
  # The pls package prefers the data in a data frame where the outcome
  # and predictors are in _matrices_. To make sure this is formatted
  # properly, use the `I()` function to inhibit `data.frame()` from making
  # all the individual columns. `pls_format` should have two columns.
  pls_format <- data.frame(
    endpoints = I(y_mat),
    measurements = I(x_mat)
  )
  # Fit the model
  mod <- plsr(endpoints ~ measurements, data = pls_format)
  
  # Get the proportion of the predictor variance that is explained
  # by the model for different number of components. 
  xve <- explvar(mod)/100 

  # To do the same for the outcome, it is more complex. This code 
  # was extracted from pls:::summary.mvr. 
  explained <- 
    drop(pls::R2(mod, estimate = "train", intercept = FALSE)$val) %>% 
    # transpose so that components are in rows
    t() %>% 
    as_tibble() %>%
    # Add the predictor proportions
    mutate(predictors = cumsum(xve) %>% as.vector(),
           components = seq_along(xve)) %>%
    # Put into a tidy format that is tall
    pivot_longer(
      cols = c(-components),
      names_to = "source",
      values_to = "proportion"
    )
}
```

We compute this data frame for each resample and save the results in the different columns. 

```{r get-estimates}
folds <- 
  folds %>%
  mutate(var = map(recipes, get_var_explained),
         var = unname(var))
```

To extract and aggregate these data, simple row binding can be used to stack the data vertically. Most of the action happens in the first 15 components so let's filter the data and compute the _average_ proportion.

```{r collapse-and-average}
variance_data <- 
  bind_rows(folds[["var"]]) %>%
  filter(components <= 15) %>%
  group_by(components, source) %>%
  summarize(proportion = mean(proportion))
```

The plot below shows that, if the protein measurement is important, you might require 10 or so components to achieve a good representation of that outcome. Note that the predictor variance is captured extremely well using a single component. This is due to the high degree of correlation in those data. 

```{r plot, fig.width=6, fig.height=4.25,  out.width = '100%'}
ggplot(variance_data, aes(x = components, y = proportion, col = source)) + 
  geom_line(alpha = 0.5, size = 1.2) + 
  geom_point() 
```


## Session information

```{r si, echo = FALSE}
small_session(pkgs)
```
 
